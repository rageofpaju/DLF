{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c613d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.image import resize_with_pad\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    load_img, \n",
    "    img_to_array, \n",
    "    ImageDataGenerator,\n",
    "    array_to_img,\n",
    "    save_img\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07cd7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b58ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 224\n",
    "TARGET_WIDTH = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ca101",
   "metadata": {},
   "source": [
    "# ==================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519d120",
   "metadata": {},
   "source": [
    "# This is where the NN modelling will go\n",
    "## For NN modelling I will use the train-val-test set obtained from splitfolders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1d5b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78da85e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4261 images belonging to 9 classes.\n",
      "Found 1418 images belonging to 9 classes.\n",
      "Found 1429 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 256\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    'C:/temp_workfolder/rbc_keras/keras_split/train',\n",
    "    target_size = (TARGET_HEIGHT, TARGET_WIDTH),\n",
    "    batch_size = 64,\n",
    "    class_mode = 'categorical',\n",
    "    interpolation='nearest',\n",
    "    seed = 42,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    'C:/temp_workfolder/rbc_keras/keras_split/val',\n",
    "    target_size = (TARGET_HEIGHT, TARGET_WIDTH),\n",
    "    batch_size = 64,\n",
    "    class_mode = 'categorical',\n",
    "    interpolation='nearest',\n",
    "    seed = 42,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    'C:/temp_workfolder/rbc_keras/keras_split/test',\n",
    "    target_size = (TARGET_HEIGHT, TARGET_WIDTH),\n",
    "    batch_size = 64,\n",
    "    class_mode = 'categorical',   #'categorical'\n",
    "    interpolation='nearest',\n",
    "    seed = 42,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99402509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acantocyte': 0,\n",
       " 'elliptocyte': 1,\n",
       " 'hypochromic': 2,\n",
       " 'normal': 3,\n",
       " 'pencil': 4,\n",
       " 'spero_bulat': 5,\n",
       " 'stomatocyte': 6,\n",
       " 'targetsel': 7,\n",
       " 'teardrop': 8}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0f7e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_gen.filenames[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74eb5bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n",
      "(64, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = next(train_gen)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862cdee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n",
      "(64, 9)\n"
     ]
    }
   ],
   "source": [
    "X_val, Y_val = next(val_gen)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24a13af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n",
      "(64, 9)\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = next(test_gen)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76553dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 9)            18441       ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,606,153\n",
      "Trainable params: 23,553,033\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33380"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model = ResNet50(weights=None, classes=9, include_top=True)#, input_shape=(96, 96, 3))\n",
    "resnet_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])\n",
    "print(resnet_model.summary())\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa6706c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc1d6333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n01930112', 'nematode', 0.2494993), ('n02317335', 'starfish', 0.23845997), ('n02321529', 'sea_cucumber', 0.19629721)]\n"
     ]
    }
   ],
   "source": [
    "res_img_path = 'C:/temp_workfolder/rbc_keras/keras_split/test/elliptocyte/T3-K1-0049 objek#27.png'\n",
    "res_img = load_img(res_img_path, target_size=(224, 224))\n",
    "res_x = img_to_array(res_img)\n",
    "res_x = np.expand_dims(res_x, axis=0)\n",
    "res_x = preprocess_input(res_x)\n",
    "\n",
    "res_pred = resnet_model.predict(res_x)\n",
    "\n",
    "print('Predicted:', decode_predictions(res_pred, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dac10d05",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)            (None, 47, 47, 32)   864         ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 47, 47, 32)  96          ['conv2d_188[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_188 (Activation)    (None, 47, 47, 32)   0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)            (None, 45, 45, 32)   9216        ['activation_188[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 45, 45, 32)  96          ['conv2d_189[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_189 (Activation)    (None, 45, 45, 32)   0           ['batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)            (None, 45, 45, 64)   18432       ['activation_189[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 45, 45, 64)  192         ['conv2d_190[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_190 (Activation)    (None, 45, 45, 64)   0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 22, 22, 64)  0           ['activation_190[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)            (None, 22, 22, 80)   5120        ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 22, 22, 80)  240         ['conv2d_191[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_191 (Activation)    (None, 22, 22, 80)   0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)            (None, 20, 20, 192)  138240      ['activation_191[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 20, 20, 192)  576        ['conv2d_192[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_192 (Activation)    (None, 20, 20, 192)  0           ['batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 9, 9, 192)   0           ['activation_192[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)            (None, 9, 9, 64)     12288       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 9, 9, 64)    192         ['conv2d_196[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_196 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)            (None, 9, 9, 48)     9216        ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)            (None, 9, 9, 96)     55296       ['activation_196[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 9, 9, 48)    144         ['conv2d_194[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 9, 9, 96)    288         ['conv2d_197[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_194 (Activation)    (None, 9, 9, 48)     0           ['batch_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " activation_197 (Activation)    (None, 9, 9, 96)     0           ['batch_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_18 (AverageP  (None, 9, 9, 192)   0           ['max_pooling2d_9[0][0]']        \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)            (None, 9, 9, 64)     12288       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)            (None, 9, 9, 64)     76800       ['activation_194[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)            (None, 9, 9, 96)     82944       ['activation_197[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)            (None, 9, 9, 32)     6144        ['average_pooling2d_18[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 9, 9, 64)    192         ['conv2d_193[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 9, 9, 64)    192         ['conv2d_195[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 9, 9, 96)    288         ['conv2d_198[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 9, 9, 32)    96          ['conv2d_199[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_193 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " activation_195 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " activation_198 (Activation)    (None, 9, 9, 96)     0           ['batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " activation_199 (Activation)    (None, 9, 9, 32)     0           ['batch_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 9, 9, 256)    0           ['activation_193[0][0]',         \n",
      "                                                                  'activation_195[0][0]',         \n",
      "                                                                  'activation_198[0][0]',         \n",
      "                                                                  'activation_199[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)            (None, 9, 9, 64)     16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 9, 9, 64)    192         ['conv2d_203[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)            (None, 9, 9, 48)     12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)            (None, 9, 9, 96)     55296       ['activation_203[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 9, 9, 48)    144         ['conv2d_201[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 9, 9, 96)    288         ['conv2d_204[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_201 (Activation)    (None, 9, 9, 48)     0           ['batch_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 9, 9, 96)     0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_19 (AverageP  (None, 9, 9, 256)   0           ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)            (None, 9, 9, 64)     16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)            (None, 9, 9, 64)     76800       ['activation_201[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)            (None, 9, 9, 96)     82944       ['activation_204[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)            (None, 9, 9, 64)     16384       ['average_pooling2d_19[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 9, 9, 64)    192         ['conv2d_200[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 9, 9, 64)    192         ['conv2d_202[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 9, 9, 96)    288         ['conv2d_205[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 9, 9, 64)    192         ['conv2d_206[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_200 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " activation_202 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 9, 9, 96)     0           ['batch_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 9, 9, 288)    0           ['activation_200[0][0]',         \n",
      "                                                                  'activation_202[0][0]',         \n",
      "                                                                  'activation_205[0][0]',         \n",
      "                                                                  'activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)            (None, 9, 9, 64)     18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 9, 9, 64)    192         ['conv2d_210[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)            (None, 9, 9, 48)     13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)            (None, 9, 9, 96)     55296       ['activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 9, 9, 48)    144         ['conv2d_208[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 9, 9, 96)    288         ['conv2d_211[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 9, 9, 48)     0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 9, 9, 96)     0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_20 (AverageP  (None, 9, 9, 288)   0           ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)            (None, 9, 9, 64)     18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)            (None, 9, 9, 64)     76800       ['activation_208[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)            (None, 9, 9, 96)     82944       ['activation_211[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)            (None, 9, 9, 64)     18432       ['average_pooling2d_20[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 9, 9, 64)    192         ['conv2d_207[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 9, 9, 64)    192         ['conv2d_209[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 9, 9, 96)    288         ['conv2d_212[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 9, 9, 64)    192         ['conv2d_213[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 9, 9, 96)     0           ['batch_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 9, 9, 288)    0           ['activation_207[0][0]',         \n",
      "                                                                  'activation_209[0][0]',         \n",
      "                                                                  'activation_212[0][0]',         \n",
      "                                                                  'activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)            (None, 9, 9, 64)     18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 9, 9, 64)    192         ['conv2d_215[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 9, 9, 64)     0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 9, 9, 96)     55296       ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 9, 9, 96)    288         ['conv2d_216[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 9, 9, 96)     0           ['batch_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)            (None, 4, 4, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)            (None, 4, 4, 96)     82944       ['activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 4, 4, 384)   1152        ['conv2d_214[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 4, 4, 96)    288         ['conv2d_217[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 4, 4, 384)    0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 4, 4, 96)     0           ['batch_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 4, 4, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 4, 4, 768)    0           ['activation_214[0][0]',         \n",
      "                                                                  'activation_217[0][0]',         \n",
      "                                                                  'max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 4, 4, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 4, 4, 128)   384         ['conv2d_222[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_222[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 4, 4, 128)   384         ['conv2d_223[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 4, 4, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 4, 4, 128)   384         ['conv2d_219[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 4, 4, 128)   384         ['conv2d_224[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 4, 4, 128)   384         ['conv2d_220[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 4, 4, 128)   384         ['conv2d_225[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_21 (AverageP  (None, 4, 4, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 4, 4, 192)    172032      ['activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 4, 4, 192)    172032      ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_21[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 4, 4, 192)   576         ['conv2d_218[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 4, 4, 192)   576         ['conv2d_221[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 4, 4, 192)   576         ['conv2d_226[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 4, 4, 192)   576         ['conv2d_227[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 4, 4, 768)    0           ['activation_218[0][0]',         \n",
      "                                                                  'activation_221[0][0]',         \n",
      "                                                                  'activation_226[0][0]',         \n",
      "                                                                  'activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 4, 4, 160)   480         ['conv2d_232[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 4, 4, 160)   480         ['conv2d_233[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 4, 4, 160)   480         ['conv2d_229[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 4, 4, 160)   480         ['conv2d_234[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 4, 4, 160)   480         ['conv2d_230[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 4, 4, 160)   480         ['conv2d_235[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_22 (AverageP  (None, 4, 4, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_22[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 4, 4, 192)   576         ['conv2d_228[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 4, 4, 192)   576         ['conv2d_231[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 4, 4, 192)   576         ['conv2d_236[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 4, 4, 192)   576         ['conv2d_237[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 4, 4, 768)    0           ['activation_228[0][0]',         \n",
      "                                                                  'activation_231[0][0]',         \n",
      "                                                                  'activation_236[0][0]',         \n",
      "                                                                  'activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 4, 4, 160)   480         ['conv2d_242[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 4, 4, 160)   480         ['conv2d_243[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 4, 4, 160)   480         ['conv2d_239[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_244 (Batch  (None, 4, 4, 160)   480         ['conv2d_244[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 4, 4, 160)   480         ['conv2d_240[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_245 (Batch  (None, 4, 4, 160)   480         ['conv2d_245[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_245[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_23 (AverageP  (None, 4, 4, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_240[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_23[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 4, 4, 192)   576         ['conv2d_238[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 4, 4, 192)   576         ['conv2d_241[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_246 (Batch  (None, 4, 4, 192)   576         ['conv2d_246[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 4, 4, 192)   576         ['conv2d_247[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 4, 4, 768)    0           ['activation_238[0][0]',         \n",
      "                                                                  'activation_241[0][0]',         \n",
      "                                                                  'activation_246[0][0]',         \n",
      "                                                                  'activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 4, 4, 192)   576         ['conv2d_252[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_252[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 4, 4, 192)   576         ['conv2d_253[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_253[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_253[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 4, 4, 192)   576         ['conv2d_249[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 4, 4, 192)   576         ['conv2d_254[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_249[0][0]']\n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 4, 4, 192)   576         ['conv2d_250[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 4, 4, 192)   576         ['conv2d_255[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_24 (AverageP  (None, 4, 4, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 4, 4, 192)   576         ['conv2d_248[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 4, 4, 192)   576         ['conv2d_251[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 4, 4, 192)   576         ['conv2d_256[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 4, 4, 192)   576         ['conv2d_257[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_251[0][0]']\n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 4, 4, 768)    0           ['activation_248[0][0]',         \n",
      "                                                                  'activation_251[0][0]',         \n",
      "                                                                  'activation_256[0][0]',         \n",
      "                                                                  'activation_257[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 4, 4, 192)   576         ['conv2d_260[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_260 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_260[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 4, 4, 192)   576         ['conv2d_261[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_261 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_258 (Batch  (None, 4, 4, 192)   576         ['conv2d_258[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 4, 4, 192)   576         ['conv2d_262[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_258 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " activation_262 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)            (None, 1, 1, 320)    552960      ['activation_258[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 1, 1, 192)    331776      ['activation_262[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 1, 1, 320)   960         ['conv2d_259[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 1, 1, 192)   576         ['conv2d_263[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_259 (Activation)    (None, 1, 1, 320)    0           ['batch_normalization_259[0][0]']\n",
      "                                                                                                  \n",
      " activation_263 (Activation)    (None, 1, 1, 192)    0           ['batch_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 1, 1, 768)   0           ['mixed7[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 1, 1, 1280)   0           ['activation_259[0][0]',         \n",
      "                                                                  'activation_263[0][0]',         \n",
      "                                                                  'max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 1, 1, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_268 (Batch  (None, 1, 1, 448)   1344        ['conv2d_268[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_268 (Activation)    (None, 1, 1, 448)    0           ['batch_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 1, 1, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 1, 1, 384)    1548288     ['activation_268[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_265 (Batch  (None, 1, 1, 384)   1152        ['conv2d_265[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_269 (Batch  (None, 1, 1, 384)   1152        ['conv2d_269[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_265 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_265[0][0]']\n",
      "                                                                                                  \n",
      " activation_269 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_269[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_269[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_25 (AverageP  (None, 1, 1, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 1, 1, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_266 (Batch  (None, 1, 1, 384)   1152        ['conv2d_266[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_267 (Batch  (None, 1, 1, 384)   1152        ['conv2d_267[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 1, 1, 384)   1152        ['conv2d_270[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 1, 1, 384)   1152        ['conv2d_271[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 1, 1, 192)    245760      ['average_pooling2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 1, 1, 320)   960         ['conv2d_264[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_266 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " activation_267 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " activation_270 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " activation_271 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 1, 1, 192)   576         ['conv2d_272[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_264 (Activation)    (None, 1, 1, 320)    0           ['batch_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 1, 1, 768)    0           ['activation_266[0][0]',         \n",
      "                                                                  'activation_267[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1, 1, 768)    0           ['activation_270[0][0]',         \n",
      "                                                                  'activation_271[0][0]']         \n",
      "                                                                                                  \n",
      " activation_272 (Activation)    (None, 1, 1, 192)    0           ['batch_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 1, 1, 2048)   0           ['activation_264[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_4[0][0]',          \n",
      "                                                                  'activation_272[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)            (None, 1, 1, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 1, 1, 448)   1344        ['conv2d_277[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_277 (Activation)    (None, 1, 1, 448)    0           ['batch_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)            (None, 1, 1, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)            (None, 1, 1, 384)    1548288     ['activation_277[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 1, 1, 384)   1152        ['conv2d_274[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 1, 1, 384)   1152        ['conv2d_278[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_274 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " activation_278 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_26 (AverageP  (None, 1, 1, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)            (None, 1, 1, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 1, 1, 384)   1152        ['conv2d_275[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 1, 1, 384)   1152        ['conv2d_276[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_279 (Batch  (None, 1, 1, 384)   1152        ['conv2d_279[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_280 (Batch  (None, 1, 1, 384)   1152        ['conv2d_280[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)            (None, 1, 1, 192)    393216      ['average_pooling2d_26[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 1, 1, 320)   960         ['conv2d_273[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_275 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " activation_276 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " activation_279 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " activation_280 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_281 (Batch  (None, 1, 1, 192)   576         ['conv2d_281[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_273 (Activation)    (None, 1, 1, 320)    0           ['batch_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 1, 1, 768)    0           ['activation_275[0][0]',         \n",
      "                                                                  'activation_276[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 1, 1, 768)    0           ['activation_279[0][0]',         \n",
      "                                                                  'activation_280[0][0]']         \n",
      "                                                                                                  \n",
      " activation_281 (Activation)    (None, 1, 1, 192)    0           ['batch_normalization_281[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 1, 1, 2048)   0           ['activation_273[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_5[0][0]',          \n",
      "                                                                  'activation_281[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
    "inception_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b769e119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 9)                 36873     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,297,417\n",
      "Trainable params: 134,297,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_model = VGG16(include_top=True,\n",
    "                    #input_shape=(TARGET_HEIGHT,TARGET_WIDTH,3),\n",
    "                    weights=None,\n",
    "                    classes=9)\n",
    "vgg16_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "gc.collect()\n",
    "vgg16_model.summary()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "508bbcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.250, max:    1.000, cur:    1.000)\n",
      "\tvalidation       \t (min:    0.250, max:    0.250, cur:    0.250)\n",
      "Loss\n",
      "\ttraining         \t (min:    0.002, max:    4.376, cur:    0.003)\n",
      "\tvalidation       \t (min:    2.114, max:   73.727, cur:   73.727)\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/2 [==============================] - 1s 707ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 73.7268 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97760"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet_model.fit(X_train,\n",
    "               Y_train,\n",
    "               epochs=100,\n",
    "               #steps_per_epoch=32,\n",
    "               validation_data=(X_val,Y_val),\n",
    "               validation_freq=1,\n",
    "               callbacks=[EarlyStopping(patience=16, verbose=0),PlotLossesKeras()]\n",
    "              )\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b967757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.094, max:    0.328, cur:    0.094)\n",
      "\tvalidation       \t (min:    0.141, max:    0.141, cur:    0.141)\n",
      "Loss\n",
      "\ttraining         \t (min:    2.186, max:    8.551, cur:    2.186)\n",
      "\tvalidation       \t (min:    2.113, max:    2.187, cur:    2.113)\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 2.1858 - accuracy: 0.0938 - val_loss: 2.1131 - val_accuracy: 0.1406\n",
      "Epoch 3/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1250 - accuracy: 0.0312"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Could not synchronize CUDA stream: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvgg16_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;66;43;03m#steps_per_epoch=32,\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPlotLossesKeras\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1117\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1115\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numpy_internal()\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1117\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInternalError\u001b[0m: Could not synchronize CUDA stream: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated"
     ]
    }
   ],
   "source": [
    "vgg16_model.fit(X_train,\n",
    "               Y_train,\n",
    "               epochs=100,\n",
    "               #steps_per_epoch=32,\n",
    "               validation_data=(X_val,Y_val),\n",
    "               validation_freq=1,\n",
    "               callbacks=[EarlyStopping(patience=16, verbose=0),PlotLossesKeras()]\n",
    "              )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85a090a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Custom\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model_test \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m      4\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(TARGET_HEIGHT,TARGET_WIDTH,\u001b[38;5;241m3\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#layers.BatchNormalization(),\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPool2D(),\n\u001b[0;32m      7\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#layers.BatchNormalization(),\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPool2D(),\n\u001b[0;32m     10\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#layers.BatchNormalization(),\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPool2D(),\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#64\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#128\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#128\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \n\u001b[0;32m     18\u001b[0m     layers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     19\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m768\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),   \u001b[38;5;66;03m#1024\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.9\u001b[39m),\n\u001b[0;32m     21\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),    \u001b[38;5;66;03m#1024\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.9\u001b[39m),\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#layers.Dense(768, activation='relu'),\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#layers.Dropout(0.6),\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#layers.Dense(64, activation='relu'),\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#layers.Dropout(0.8),\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m9\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m ])\n\u001b[0;32m     30\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session() \n\u001b[0;32m     31\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Custom\n",
    "\n",
    "model_test = Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(TARGET_HEIGHT,TARGET_WIDTH,3), padding=\"same\"),\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"same\"),\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"same\"),\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    #64\n",
    "    #128\n",
    "    #128\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(768, activation='relu'),   #1024\n",
    "    layers.Dropout(0.9),\n",
    "    layers.Dense(256, activation='relu'),    #1024\n",
    "    layers.Dropout(0.9),\n",
    "    #layers.Dense(768, activation='relu'),\n",
    "    #layers.Dropout(0.6),\n",
    "\n",
    "    #layers.Dense(64, activation='relu'),\n",
    "    #layers.Dropout(0.8),\n",
    "    layers.Dense(9, activation='softmax')\n",
    "])\n",
    "tf.keras.backend.clear_session() \n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2ac5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1c00bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 768)               25166592  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               196864    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 2313      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,589,001\n",
      "Trainable params: 25,589,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_test.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b2dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 8s 35ms/step - loss: 2.3156 - accuracy: 0.1745 - val_loss: 2.0959 - val_accuracy: 0.2842\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.0873 - accuracy: 0.2435 - val_loss: 2.0227 - val_accuracy: 0.2842\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.9837 - accuracy: 0.2891 - val_loss: 1.8652 - val_accuracy: 0.2842\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.9138 - accuracy: 0.3086 - val_loss: 1.6934 - val_accuracy: 0.4668\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.8044 - accuracy: 0.3555 - val_loss: 1.6169 - val_accuracy: 0.4727\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.7554 - accuracy: 0.3763 - val_loss: 1.6246 - val_accuracy: 0.4951\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.6956 - accuracy: 0.4180 - val_loss: 1.4881 - val_accuracy: 0.5049\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.6099 - accuracy: 0.4349 - val_loss: 1.4620 - val_accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.5744 - accuracy: 0.4635 - val_loss: 1.4408 - val_accuracy: 0.5205\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.5257 - accuracy: 0.4701 - val_loss: 1.4639 - val_accuracy: 0.5293\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.5460 - accuracy: 0.4714 - val_loss: 1.4670 - val_accuracy: 0.5371\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.4469 - accuracy: 0.5039 - val_loss: 1.3959 - val_accuracy: 0.5469\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.4516 - accuracy: 0.5052 - val_loss: 1.3691 - val_accuracy: 0.5742\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.3719 - accuracy: 0.5273 - val_loss: 1.3591 - val_accuracy: 0.5771\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.3900 - accuracy: 0.5195 - val_loss: 1.3722 - val_accuracy: 0.5879\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.3584 - accuracy: 0.5260 - val_loss: 1.3160 - val_accuracy: 0.5977\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.3329 - accuracy: 0.5260 - val_loss: 1.3255 - val_accuracy: 0.5908\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.3398 - accuracy: 0.5352 - val_loss: 1.2960 - val_accuracy: 0.5977\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.2997 - accuracy: 0.5430 - val_loss: 1.2840 - val_accuracy: 0.6016\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.2962 - accuracy: 0.5781 - val_loss: 1.2658 - val_accuracy: 0.6045\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.2291 - accuracy: 0.5911 - val_loss: 1.2412 - val_accuracy: 0.6045\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.2526 - accuracy: 0.5716 - val_loss: 1.2535 - val_accuracy: 0.6104\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.2273 - accuracy: 0.5781 - val_loss: 1.2406 - val_accuracy: 0.6064\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.2003 - accuracy: 0.5859 - val_loss: 1.2554 - val_accuracy: 0.6094\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.1665 - accuracy: 0.6081 - val_loss: 1.2179 - val_accuracy: 0.6162\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.1725 - accuracy: 0.6068 - val_loss: 1.1805 - val_accuracy: 0.6094\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.1384 - accuracy: 0.6133 - val_loss: 1.2228 - val_accuracy: 0.6143\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.0698 - accuracy: 0.6250 - val_loss: 1.2142 - val_accuracy: 0.6270\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.1068 - accuracy: 0.6146 - val_loss: 1.2479 - val_accuracy: 0.6162\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 1.0478 - accuracy: 0.6393 - val_loss: 1.2295 - val_accuracy: 0.6416\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 1.0473 - accuracy: 0.6393 - val_loss: 1.1855 - val_accuracy: 0.6289\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 1.0372 - accuracy: 0.6302 - val_loss: 1.2074 - val_accuracy: 0.6504\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 1.0149 - accuracy: 0.6419 - val_loss: 1.1424 - val_accuracy: 0.6445\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.0385 - accuracy: 0.6354 - val_loss: 1.1559 - val_accuracy: 0.6475\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.9820 - accuracy: 0.6536 - val_loss: 1.1748 - val_accuracy: 0.6396\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.9902 - accuracy: 0.6458 - val_loss: 1.1715 - val_accuracy: 0.6436\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.9977 - accuracy: 0.6445 - val_loss: 1.1433 - val_accuracy: 0.6348\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.9957 - accuracy: 0.6562 - val_loss: 1.1909 - val_accuracy: 0.6523\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 0.9439 - accuracy: 0.6458 - val_loss: 1.1689 - val_accuracy: 0.6504\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.9553 - accuracy: 0.6589 - val_loss: 1.1790 - val_accuracy: 0.6553\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.9428 - accuracy: 0.6615 - val_loss: 1.1887 - val_accuracy: 0.6475\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.9216 - accuracy: 0.6589 - val_loss: 1.2188 - val_accuracy: 0.6484\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 0.9322 - accuracy: 0.6615 - val_loss: 1.1872 - val_accuracy: 0.6416\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.8723 - accuracy: 0.6680 - val_loss: 1.1716 - val_accuracy: 0.6494\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.8868 - accuracy: 0.6602 - val_loss: 1.2205 - val_accuracy: 0.6553\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 0.8672 - accuracy: 0.6771 - val_loss: 1.2186 - val_accuracy: 0.6562\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 0.8948 - accuracy: 0.6732 - val_loss: 1.2283 - val_accuracy: 0.6465\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 0.9450 - accuracy: 0.6628 - val_loss: 1.1966 - val_accuracy: 0.6475\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.8648 - accuracy: 0.6758 - val_loss: 1.2194 - val_accuracy: 0.6611\n",
      "Epoch 00049: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1658"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size 512\n",
    "# img size 128\n",
    "# dropout 0.87\n",
    "\n",
    "model_test.fit(X_train,\n",
    "               Y_train,\n",
    "               epochs=100,\n",
    "               #steps_per_epoch=32,\n",
    "               validation_data=(X_val,Y_val),\n",
    "               validation_freq=1,\n",
    "               callbacks=[EarlyStopping(patience=16, verbose=1)]\n",
    "              )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "941e725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 2.1954 - accuracy: 0.1875 - val_loss: 2.0719 - val_accuracy: 0.2842\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.9649 - accuracy: 0.2510 - val_loss: 1.9537 - val_accuracy: 0.2842\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.8592 - accuracy: 0.2559 - val_loss: 1.8201 - val_accuracy: 0.2842\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.7658 - accuracy: 0.2998 - val_loss: 1.7025 - val_accuracy: 0.2842\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.7226 - accuracy: 0.3516 - val_loss: 1.6963 - val_accuracy: 0.4834\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.6217 - accuracy: 0.4336 - val_loss: 1.6903 - val_accuracy: 0.4639\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.5928 - accuracy: 0.4600 - val_loss: 1.5898 - val_accuracy: 0.4775\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.5316 - accuracy: 0.4941 - val_loss: 1.5366 - val_accuracy: 0.4814\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.5247 - accuracy: 0.4795 - val_loss: 1.5546 - val_accuracy: 0.4678\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.5040 - accuracy: 0.4873 - val_loss: 1.4927 - val_accuracy: 0.4941\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.4723 - accuracy: 0.4883 - val_loss: 1.4479 - val_accuracy: 0.4941\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.4540 - accuracy: 0.4961 - val_loss: 1.4360 - val_accuracy: 0.5010\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.4341 - accuracy: 0.5020 - val_loss: 1.4150 - val_accuracy: 0.4941\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.4322 - accuracy: 0.5078 - val_loss: 1.4674 - val_accuracy: 0.4805\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.4188 - accuracy: 0.5215 - val_loss: 1.4518 - val_accuracy: 0.4805\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3980 - accuracy: 0.5195 - val_loss: 1.4261 - val_accuracy: 0.5117\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3750 - accuracy: 0.5166 - val_loss: 1.3833 - val_accuracy: 0.5225\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.3942 - accuracy: 0.4980 - val_loss: 1.3834 - val_accuracy: 0.5273\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3322 - accuracy: 0.5391 - val_loss: 1.3988 - val_accuracy: 0.5117\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3552 - accuracy: 0.5293 - val_loss: 1.4189 - val_accuracy: 0.5186\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3148 - accuracy: 0.5459 - val_loss: 1.3920 - val_accuracy: 0.5039\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3410 - accuracy: 0.5527 - val_loss: 1.3860 - val_accuracy: 0.5107\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3350 - accuracy: 0.5342 - val_loss: 1.4010 - val_accuracy: 0.5176\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2935 - accuracy: 0.5488 - val_loss: 1.3894 - val_accuracy: 0.5322\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2962 - accuracy: 0.5459 - val_loss: 1.4080 - val_accuracy: 0.5225\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2677 - accuracy: 0.5479 - val_loss: 1.3666 - val_accuracy: 0.5332\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2932 - accuracy: 0.5391 - val_loss: 1.3693 - val_accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3186 - accuracy: 0.5488 - val_loss: 1.4442 - val_accuracy: 0.5586\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.3338 - accuracy: 0.5391 - val_loss: 1.4180 - val_accuracy: 0.4990\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.3294 - accuracy: 0.5254 - val_loss: 1.3799 - val_accuracy: 0.5449\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.2716 - accuracy: 0.5576 - val_loss: 1.3928 - val_accuracy: 0.5078\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2355 - accuracy: 0.5615 - val_loss: 1.3562 - val_accuracy: 0.5303\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.2581 - accuracy: 0.5586 - val_loss: 1.4023 - val_accuracy: 0.5088\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2447 - accuracy: 0.5625 - val_loss: 1.3411 - val_accuracy: 0.5586\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2613 - accuracy: 0.5771 - val_loss: 1.3622 - val_accuracy: 0.5605\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2531 - accuracy: 0.5586 - val_loss: 1.3291 - val_accuracy: 0.5576\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2653 - accuracy: 0.5557 - val_loss: 1.3508 - val_accuracy: 0.5459\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2382 - accuracy: 0.5645 - val_loss: 1.3096 - val_accuracy: 0.5967\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2032 - accuracy: 0.5801 - val_loss: 1.3549 - val_accuracy: 0.5703\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.2037 - accuracy: 0.5762 - val_loss: 1.3555 - val_accuracy: 0.5615\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1907 - accuracy: 0.5859 - val_loss: 1.3293 - val_accuracy: 0.5674\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.2004 - accuracy: 0.5801 - val_loss: 1.4088 - val_accuracy: 0.5615\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1979 - accuracy: 0.5791 - val_loss: 1.4184 - val_accuracy: 0.5771\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1758 - accuracy: 0.5898 - val_loss: 1.3496 - val_accuracy: 0.5850\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.1935 - accuracy: 0.5703 - val_loss: 1.3887 - val_accuracy: 0.5771\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1941 - accuracy: 0.5820 - val_loss: 1.3695 - val_accuracy: 0.5547\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1970 - accuracy: 0.5615 - val_loss: 1.4353 - val_accuracy: 0.5674\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.1937 - accuracy: 0.5762 - val_loss: 1.3694 - val_accuracy: 0.5830\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1813 - accuracy: 0.5908 - val_loss: 1.3847 - val_accuracy: 0.5654\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1635 - accuracy: 0.5889 - val_loss: 1.4601 - val_accuracy: 0.5703\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1744 - accuracy: 0.5908 - val_loss: 1.3895 - val_accuracy: 0.5703\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1370 - accuracy: 0.6016 - val_loss: 1.4719 - val_accuracy: 0.5820\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1519 - accuracy: 0.5996 - val_loss: 1.4381 - val_accuracy: 0.5732\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1784 - accuracy: 0.5977 - val_loss: 1.3869 - val_accuracy: 0.5605\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1418 - accuracy: 0.6045 - val_loss: 1.4771 - val_accuracy: 0.5615\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1159 - accuracy: 0.6074 - val_loss: 1.4349 - val_accuracy: 0.5605\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1368 - accuracy: 0.6045 - val_loss: 1.4573 - val_accuracy: 0.5771\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1224 - accuracy: 0.6025 - val_loss: 1.4456 - val_accuracy: 0.5801\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1736 - accuracy: 0.5967 - val_loss: 1.4075 - val_accuracy: 0.5684\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1274 - accuracy: 0.6055 - val_loss: 1.4197 - val_accuracy: 0.5830\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1222 - accuracy: 0.6104 - val_loss: 1.4633 - val_accuracy: 0.5693\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1614 - accuracy: 0.5938 - val_loss: 1.4464 - val_accuracy: 0.5693\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1171 - accuracy: 0.6191 - val_loss: 1.4339 - val_accuracy: 0.5732\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1228 - accuracy: 0.6074 - val_loss: 1.4758 - val_accuracy: 0.5811\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1190 - accuracy: 0.6221 - val_loss: 1.4561 - val_accuracy: 0.5781\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0772 - accuracy: 0.6221 - val_loss: 1.4752 - val_accuracy: 0.5977\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0593 - accuracy: 0.6338 - val_loss: 1.4469 - val_accuracy: 0.5879\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0935 - accuracy: 0.6133 - val_loss: 1.5370 - val_accuracy: 0.5684\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1325 - accuracy: 0.6143 - val_loss: 1.6072 - val_accuracy: 0.5840\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1126 - accuracy: 0.6074 - val_loss: 1.4901 - val_accuracy: 0.5762\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0661 - accuracy: 0.6221 - val_loss: 1.6536 - val_accuracy: 0.5889\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0943 - accuracy: 0.6133 - val_loss: 1.4593 - val_accuracy: 0.5771\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1337 - accuracy: 0.6143 - val_loss: 1.4340 - val_accuracy: 0.5635\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0960 - accuracy: 0.6133 - val_loss: 1.4687 - val_accuracy: 0.5977\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0705 - accuracy: 0.6201 - val_loss: 1.4929 - val_accuracy: 0.5742\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0622 - accuracy: 0.6230 - val_loss: 1.5623 - val_accuracy: 0.5879\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0973 - accuracy: 0.6172 - val_loss: 1.4878 - val_accuracy: 0.5938\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0658 - accuracy: 0.6230 - val_loss: 1.5341 - val_accuracy: 0.5771\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0860 - accuracy: 0.6201 - val_loss: 1.5840 - val_accuracy: 0.5742\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0899 - accuracy: 0.6250 - val_loss: 1.6009 - val_accuracy: 0.5801\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1053 - accuracy: 0.6133 - val_loss: 1.4419 - val_accuracy: 0.5908\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0601 - accuracy: 0.6309 - val_loss: 1.5109 - val_accuracy: 0.5840\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0651 - accuracy: 0.6240 - val_loss: 1.5543 - val_accuracy: 0.5947\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0462 - accuracy: 0.6191 - val_loss: 1.5229 - val_accuracy: 0.5957\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0469 - accuracy: 0.6201 - val_loss: 1.5211 - val_accuracy: 0.5977\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0283 - accuracy: 0.6289 - val_loss: 1.5642 - val_accuracy: 0.5801\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0464 - accuracy: 0.6318 - val_loss: 1.5849 - val_accuracy: 0.5918\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0426 - accuracy: 0.6279 - val_loss: 1.4870 - val_accuracy: 0.5840\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0824 - accuracy: 0.6211 - val_loss: 1.6336 - val_accuracy: 0.5889\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0511 - accuracy: 0.6250 - val_loss: 1.7256 - val_accuracy: 0.5977\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0559 - accuracy: 0.6250 - val_loss: 1.7031 - val_accuracy: 0.5967\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0293 - accuracy: 0.6348 - val_loss: 1.6961 - val_accuracy: 0.5928\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.0142 - accuracy: 0.6309 - val_loss: 1.6552 - val_accuracy: 0.5967\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0218 - accuracy: 0.6367 - val_loss: 1.5233 - val_accuracy: 0.5840\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.9974 - accuracy: 0.6494 - val_loss: 1.4983 - val_accuracy: 0.6025\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.9987 - accuracy: 0.6377 - val_loss: 1.5453 - val_accuracy: 0.5889\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0146 - accuracy: 0.6377 - val_loss: 1.6641 - val_accuracy: 0.5967\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0094 - accuracy: 0.6328 - val_loss: 1.4716 - val_accuracy: 0.5996\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.9934 - accuracy: 0.6445 - val_loss: 1.5540 - val_accuracy: 0.5898\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.0291 - accuracy: 0.6279 - val_loss: 1.5677 - val_accuracy: 0.5996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1a659f520>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size 1024\n",
    "\n",
    "model_test.fit(\n",
    "          X_train,\n",
    "          Y_train,\n",
    "          epochs=100,\n",
    "          validation_data=(X_val,Y_val),\n",
    "          validation_freq=1,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3bac9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 2.3662 - accuracy: 0.1914 - val_loss: 2.1377 - val_accuracy: 0.3008\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0340 - accuracy: 0.2480 - val_loss: 2.0451 - val_accuracy: 0.3008\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9566 - accuracy: 0.2598 - val_loss: 1.9999 - val_accuracy: 0.3008\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9237 - accuracy: 0.2656 - val_loss: 1.9517 - val_accuracy: 0.3008\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8344 - accuracy: 0.2617 - val_loss: 1.8354 - val_accuracy: 0.3008\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7904 - accuracy: 0.2617 - val_loss: 1.8023 - val_accuracy: 0.3008\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7308 - accuracy: 0.2891 - val_loss: 1.7267 - val_accuracy: 0.3008\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6905 - accuracy: 0.3105 - val_loss: 1.7119 - val_accuracy: 0.3008\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5781 - accuracy: 0.3477 - val_loss: 1.6358 - val_accuracy: 0.5117\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5659 - accuracy: 0.4258 - val_loss: 1.5529 - val_accuracy: 0.5137\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5219 - accuracy: 0.4824 - val_loss: 1.6055 - val_accuracy: 0.5156\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5155 - accuracy: 0.4961 - val_loss: 1.5167 - val_accuracy: 0.5156\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5007 - accuracy: 0.4844 - val_loss: 1.4999 - val_accuracy: 0.5137\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5166 - accuracy: 0.5078 - val_loss: 1.5225 - val_accuracy: 0.5117\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4710 - accuracy: 0.4941 - val_loss: 1.4679 - val_accuracy: 0.5098\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4575 - accuracy: 0.5156 - val_loss: 1.4971 - val_accuracy: 0.5059\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4248 - accuracy: 0.5117 - val_loss: 1.4817 - val_accuracy: 0.5059\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4075 - accuracy: 0.5156 - val_loss: 1.4580 - val_accuracy: 0.5059\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3548 - accuracy: 0.5273 - val_loss: 1.3906 - val_accuracy: 0.5332\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3844 - accuracy: 0.5234 - val_loss: 1.3815 - val_accuracy: 0.5332\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3416 - accuracy: 0.5449 - val_loss: 1.4384 - val_accuracy: 0.5059\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3746 - accuracy: 0.5273 - val_loss: 1.3865 - val_accuracy: 0.5254\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3200 - accuracy: 0.5469 - val_loss: 1.3799 - val_accuracy: 0.5293\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3137 - accuracy: 0.5293 - val_loss: 1.3609 - val_accuracy: 0.5273\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3387 - accuracy: 0.5254 - val_loss: 1.3272 - val_accuracy: 0.5469\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3162 - accuracy: 0.5254 - val_loss: 1.4307 - val_accuracy: 0.4883\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3095 - accuracy: 0.5391 - val_loss: 1.3401 - val_accuracy: 0.5352\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2800 - accuracy: 0.5566 - val_loss: 1.3458 - val_accuracy: 0.5391\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2745 - accuracy: 0.5449 - val_loss: 1.3436 - val_accuracy: 0.5215\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2681 - accuracy: 0.5801 - val_loss: 1.3669 - val_accuracy: 0.5137\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2777 - accuracy: 0.5371 - val_loss: 1.3542 - val_accuracy: 0.5176\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3060 - accuracy: 0.5469 - val_loss: 1.4252 - val_accuracy: 0.4883\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2839 - accuracy: 0.5605 - val_loss: 1.3476 - val_accuracy: 0.5156\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2614 - accuracy: 0.5645 - val_loss: 1.3685 - val_accuracy: 0.5332\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2438 - accuracy: 0.5527 - val_loss: 1.3339 - val_accuracy: 0.5410\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2631 - accuracy: 0.5605 - val_loss: 1.3290 - val_accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2463 - accuracy: 0.5664 - val_loss: 1.3392 - val_accuracy: 0.5234\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2244 - accuracy: 0.5703 - val_loss: 1.3694 - val_accuracy: 0.5332\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1880 - accuracy: 0.5996 - val_loss: 1.3510 - val_accuracy: 0.5371\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1621 - accuracy: 0.5898 - val_loss: 1.3459 - val_accuracy: 0.5371\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2079 - accuracy: 0.5879 - val_loss: 1.3456 - val_accuracy: 0.5469\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1894 - accuracy: 0.5762 - val_loss: 1.3125 - val_accuracy: 0.5586\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1851 - accuracy: 0.5801 - val_loss: 1.3688 - val_accuracy: 0.5352\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1660 - accuracy: 0.6074 - val_loss: 1.3427 - val_accuracy: 0.5449\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1851 - accuracy: 0.5859 - val_loss: 1.3443 - val_accuracy: 0.5684\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1486 - accuracy: 0.5840 - val_loss: 1.3448 - val_accuracy: 0.5293\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1533 - accuracy: 0.5898 - val_loss: 1.3584 - val_accuracy: 0.5508\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1320 - accuracy: 0.5977 - val_loss: 1.3877 - val_accuracy: 0.5645\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2143 - accuracy: 0.5918 - val_loss: 1.3424 - val_accuracy: 0.5391\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1677 - accuracy: 0.5957 - val_loss: 1.3493 - val_accuracy: 0.5703\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1556 - accuracy: 0.5898 - val_loss: 1.3112 - val_accuracy: 0.5547\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1777 - accuracy: 0.5762 - val_loss: 1.3363 - val_accuracy: 0.5566\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1567 - accuracy: 0.5918 - val_loss: 1.3661 - val_accuracy: 0.5430\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1113 - accuracy: 0.6094 - val_loss: 1.3497 - val_accuracy: 0.5801\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1234 - accuracy: 0.6074 - val_loss: 1.3672 - val_accuracy: 0.5742\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1438 - accuracy: 0.6094 - val_loss: 1.4078 - val_accuracy: 0.5488\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1286 - accuracy: 0.6035 - val_loss: 1.4195 - val_accuracy: 0.5664\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1122 - accuracy: 0.6289 - val_loss: 1.3391 - val_accuracy: 0.5625\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1067 - accuracy: 0.6230 - val_loss: 1.3665 - val_accuracy: 0.5996\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1286 - accuracy: 0.5996 - val_loss: 1.3329 - val_accuracy: 0.5664\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1438 - accuracy: 0.6113 - val_loss: 1.3620 - val_accuracy: 0.5586\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1506 - accuracy: 0.5996 - val_loss: 1.3798 - val_accuracy: 0.5645\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0975 - accuracy: 0.6094 - val_loss: 1.3732 - val_accuracy: 0.5664\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1021 - accuracy: 0.6094 - val_loss: 1.3988 - val_accuracy: 0.5527\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0841 - accuracy: 0.6152 - val_loss: 1.4597 - val_accuracy: 0.5762\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0876 - accuracy: 0.6152 - val_loss: 1.3991 - val_accuracy: 0.5742\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1092 - accuracy: 0.6152 - val_loss: 1.3593 - val_accuracy: 0.5703\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0612 - accuracy: 0.6270 - val_loss: 1.3811 - val_accuracy: 0.5801\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0636 - accuracy: 0.6172 - val_loss: 1.4301 - val_accuracy: 0.5781\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1081 - accuracy: 0.6094 - val_loss: 1.4081 - val_accuracy: 0.5645\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0839 - accuracy: 0.6191 - val_loss: 1.4712 - val_accuracy: 0.5918\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1289 - accuracy: 0.6152 - val_loss: 1.3804 - val_accuracy: 0.5625\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0963 - accuracy: 0.6348 - val_loss: 1.4169 - val_accuracy: 0.5430\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0882 - accuracy: 0.6328 - val_loss: 1.5149 - val_accuracy: 0.5820\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0782 - accuracy: 0.6270 - val_loss: 1.4233 - val_accuracy: 0.5625\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1161 - accuracy: 0.6094 - val_loss: 1.4651 - val_accuracy: 0.5645\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0606 - accuracy: 0.6133 - val_loss: 1.5154 - val_accuracy: 0.6016\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0859 - accuracy: 0.6172 - val_loss: 1.4238 - val_accuracy: 0.5664\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0857 - accuracy: 0.6289 - val_loss: 1.4483 - val_accuracy: 0.5742\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0420 - accuracy: 0.6348 - val_loss: 1.4344 - val_accuracy: 0.5684\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0161 - accuracy: 0.6484 - val_loss: 1.3858 - val_accuracy: 0.5918\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0294 - accuracy: 0.6484 - val_loss: 1.3922 - val_accuracy: 0.5840\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0271 - accuracy: 0.6484 - val_loss: 1.3676 - val_accuracy: 0.5879\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0551 - accuracy: 0.6348 - val_loss: 1.3840 - val_accuracy: 0.5703\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0856 - accuracy: 0.6152 - val_loss: 1.3695 - val_accuracy: 0.5977\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0065 - accuracy: 0.6387 - val_loss: 1.4430 - val_accuracy: 0.5879\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0050 - accuracy: 0.6406 - val_loss: 1.4017 - val_accuracy: 0.6035\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0374 - accuracy: 0.6543 - val_loss: 1.4233 - val_accuracy: 0.5996\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0349 - accuracy: 0.6367 - val_loss: 1.4195 - val_accuracy: 0.5742\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9976 - accuracy: 0.6523 - val_loss: 1.4297 - val_accuracy: 0.6016\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0135 - accuracy: 0.6445 - val_loss: 1.4099 - val_accuracy: 0.5879\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9978 - accuracy: 0.6484 - val_loss: 1.4598 - val_accuracy: 0.5918\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0431 - accuracy: 0.6523 - val_loss: 1.4527 - val_accuracy: 0.5957\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0272 - accuracy: 0.6504 - val_loss: 1.4596 - val_accuracy: 0.6016\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0509 - accuracy: 0.6387 - val_loss: 1.5313 - val_accuracy: 0.5762\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0060 - accuracy: 0.6406 - val_loss: 1.4549 - val_accuracy: 0.5996\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0361 - accuracy: 0.6387 - val_loss: 1.4561 - val_accuracy: 0.5840\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9997 - accuracy: 0.6504 - val_loss: 1.4341 - val_accuracy: 0.5840\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0252 - accuracy: 0.6484 - val_loss: 1.5539 - val_accuracy: 0.6016\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9679 - accuracy: 0.6562 - val_loss: 1.4619 - val_accuracy: 0.6035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1a6589c10>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size 512\n",
    "\n",
    "model_test.fit(\n",
    "          X_train,\n",
    "          Y_train,\n",
    "          epochs=100,\n",
    "          validation_data=(X_val,Y_val),\n",
    "          validation_freq=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31bbb8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 62ms/step - loss: 2.4591 - accuracy: 0.1602 - val_loss: 2.1568 - val_accuracy: 0.2930\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 2.1402 - accuracy: 0.1914 - val_loss: 2.0647 - val_accuracy: 0.2930\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 2.1201 - accuracy: 0.2188 - val_loss: 2.0769 - val_accuracy: 0.2930\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 2.0739 - accuracy: 0.2539 - val_loss: 2.0160 - val_accuracy: 0.2930\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 2.0341 - accuracy: 0.2539 - val_loss: 2.0257 - val_accuracy: 0.2930\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 2.0164 - accuracy: 0.2461 - val_loss: 1.9201 - val_accuracy: 0.2930\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.0162 - accuracy: 0.2188 - val_loss: 1.9641 - val_accuracy: 0.2930\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.9311 - accuracy: 0.3008 - val_loss: 1.8311 - val_accuracy: 0.2930\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.8827 - accuracy: 0.3164 - val_loss: 1.8283 - val_accuracy: 0.3672\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.8354 - accuracy: 0.3242 - val_loss: 1.7070 - val_accuracy: 0.4258\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.8055 - accuracy: 0.3477 - val_loss: 1.7241 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.7092 - accuracy: 0.3750 - val_loss: 1.6075 - val_accuracy: 0.5039\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.7039 - accuracy: 0.3984 - val_loss: 1.5942 - val_accuracy: 0.5117\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.6131 - accuracy: 0.4102 - val_loss: 1.5878 - val_accuracy: 0.5156\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.6824 - accuracy: 0.3555 - val_loss: 1.5984 - val_accuracy: 0.5156\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.6375 - accuracy: 0.3672 - val_loss: 1.5689 - val_accuracy: 0.4805\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.6559 - accuracy: 0.3867 - val_loss: 1.5721 - val_accuracy: 0.5234\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1.5748 - accuracy: 0.3984 - val_loss: 1.5366 - val_accuracy: 0.5234\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1.5187 - accuracy: 0.4219 - val_loss: 1.5012 - val_accuracy: 0.5352\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.5658 - accuracy: 0.3906 - val_loss: 1.5130 - val_accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.5120 - accuracy: 0.4141 - val_loss: 1.4961 - val_accuracy: 0.5352\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.5410 - accuracy: 0.4414 - val_loss: 1.4976 - val_accuracy: 0.5273\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.4564 - accuracy: 0.4922 - val_loss: 1.4786 - val_accuracy: 0.5195\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.4740 - accuracy: 0.4531 - val_loss: 1.4738 - val_accuracy: 0.5273\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.5431 - accuracy: 0.4375 - val_loss: 1.5040 - val_accuracy: 0.5234\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.5218 - accuracy: 0.4531 - val_loss: 1.4733 - val_accuracy: 0.5273\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.4230 - accuracy: 0.4531 - val_loss: 1.4911 - val_accuracy: 0.5547\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.4487 - accuracy: 0.4609 - val_loss: 1.4819 - val_accuracy: 0.5508\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.4340 - accuracy: 0.4883 - val_loss: 1.4624 - val_accuracy: 0.5547\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.4518 - accuracy: 0.4727 - val_loss: 1.4469 - val_accuracy: 0.5508\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1.3689 - accuracy: 0.5352 - val_loss: 1.4308 - val_accuracy: 0.5352\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.3405 - accuracy: 0.4961 - val_loss: 1.4196 - val_accuracy: 0.5391\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.3849 - accuracy: 0.5195 - val_loss: 1.4208 - val_accuracy: 0.5469\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.3598 - accuracy: 0.5039 - val_loss: 1.4256 - val_accuracy: 0.5586\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1.3247 - accuracy: 0.5273 - val_loss: 1.4418 - val_accuracy: 0.5625\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1.3568 - accuracy: 0.4922 - val_loss: 1.4442 - val_accuracy: 0.5430\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.3631 - accuracy: 0.5039 - val_loss: 1.4528 - val_accuracy: 0.5391\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.3305 - accuracy: 0.5000 - val_loss: 1.4543 - val_accuracy: 0.5547\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.3804 - accuracy: 0.4688 - val_loss: 1.4315 - val_accuracy: 0.5469\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.3397 - accuracy: 0.5156 - val_loss: 1.4329 - val_accuracy: 0.5508\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.3044 - accuracy: 0.5547 - val_loss: 1.4252 - val_accuracy: 0.5547\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.3313 - accuracy: 0.4844 - val_loss: 1.4124 - val_accuracy: 0.5664\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.3057 - accuracy: 0.5000 - val_loss: 1.4198 - val_accuracy: 0.5625\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.3331 - accuracy: 0.5078 - val_loss: 1.4305 - val_accuracy: 0.5703\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.2662 - accuracy: 0.5156 - val_loss: 1.4262 - val_accuracy: 0.5781\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.3052 - accuracy: 0.5117 - val_loss: 1.4343 - val_accuracy: 0.5859\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.2790 - accuracy: 0.5156 - val_loss: 1.4419 - val_accuracy: 0.5859\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.2962 - accuracy: 0.4961 - val_loss: 1.4325 - val_accuracy: 0.5820\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.2636 - accuracy: 0.5273 - val_loss: 1.4236 - val_accuracy: 0.5781\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.2739 - accuracy: 0.5273 - val_loss: 1.4063 - val_accuracy: 0.5781\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.2166 - accuracy: 0.5117 - val_loss: 1.4097 - val_accuracy: 0.5703\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.2642 - accuracy: 0.5273 - val_loss: 1.4299 - val_accuracy: 0.5742\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.1981 - accuracy: 0.5312 - val_loss: 1.4715 - val_accuracy: 0.5977\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.2678 - accuracy: 0.5039 - val_loss: 1.4450 - val_accuracy: 0.5820\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.2684 - accuracy: 0.5391 - val_loss: 1.3921 - val_accuracy: 0.5625\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1.2306 - accuracy: 0.5195 - val_loss: 1.3912 - val_accuracy: 0.5703\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.2041 - accuracy: 0.5117 - val_loss: 1.4631 - val_accuracy: 0.5742\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.2078 - accuracy: 0.5508 - val_loss: 1.4517 - val_accuracy: 0.5781\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1837 - accuracy: 0.5859 - val_loss: 1.4654 - val_accuracy: 0.6016\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1291 - accuracy: 0.5586 - val_loss: 1.4405 - val_accuracy: 0.5898\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.2110 - accuracy: 0.5352 - val_loss: 1.4178 - val_accuracy: 0.5664\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.1474 - accuracy: 0.5352 - val_loss: 1.4219 - val_accuracy: 0.5625\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1442 - accuracy: 0.5703 - val_loss: 1.4696 - val_accuracy: 0.5898\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1467 - accuracy: 0.5312 - val_loss: 1.4922 - val_accuracy: 0.5977\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1384 - accuracy: 0.5352 - val_loss: 1.5585 - val_accuracy: 0.5781\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 1.1304 - accuracy: 0.5625 - val_loss: 1.4856 - val_accuracy: 0.5859\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 1.1372 - accuracy: 0.5586 - val_loss: 1.5459 - val_accuracy: 0.5938\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.2295 - accuracy: 0.5234 - val_loss: 1.4069 - val_accuracy: 0.5859\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.0757 - accuracy: 0.5898 - val_loss: 1.4219 - val_accuracy: 0.5703\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.1479 - accuracy: 0.5742 - val_loss: 1.3963 - val_accuracy: 0.5781\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1499 - accuracy: 0.5430 - val_loss: 1.4684 - val_accuracy: 0.5898\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1018 - accuracy: 0.5898 - val_loss: 1.4538 - val_accuracy: 0.5781\n",
      "Epoch 00072: early stopping\n"
     ]
    }
   ],
   "source": [
    "result = model_test.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    #steps_per_epoch=16,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val,Y_val),\n",
    "    callbacks=[EarlyStopping(patience=16, verbose=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5831bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 5s 38ms/step - loss: 2.2816 - accuracy: 0.2090 - val_loss: 1.9213 - val_accuracy: 0.3008\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.9520 - accuracy: 0.2949 - val_loss: 1.8112 - val_accuracy: 0.5156\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8640 - accuracy: 0.3496 - val_loss: 1.6299 - val_accuracy: 0.5156\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.6509 - accuracy: 0.4453 - val_loss: 1.4751 - val_accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5228 - accuracy: 0.4844 - val_loss: 1.3431 - val_accuracy: 0.5547\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4832 - accuracy: 0.4863 - val_loss: 1.3209 - val_accuracy: 0.5664\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3865 - accuracy: 0.4961 - val_loss: 1.3125 - val_accuracy: 0.5723\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3182 - accuracy: 0.5352 - val_loss: 1.2507 - val_accuracy: 0.6016\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3083 - accuracy: 0.5273 - val_loss: 1.2405 - val_accuracy: 0.6016\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2289 - accuracy: 0.5723 - val_loss: 1.1986 - val_accuracy: 0.6133\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2217 - accuracy: 0.5742 - val_loss: 1.1851 - val_accuracy: 0.6211\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2269 - accuracy: 0.5820 - val_loss: 1.1814 - val_accuracy: 0.6133\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.1108 - accuracy: 0.6074 - val_loss: 1.1708 - val_accuracy: 0.6074\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1568 - accuracy: 0.6270 - val_loss: 1.1349 - val_accuracy: 0.6387\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0795 - accuracy: 0.6406 - val_loss: 1.1683 - val_accuracy: 0.6406\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0327 - accuracy: 0.6230 - val_loss: 1.1175 - val_accuracy: 0.6367\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0010 - accuracy: 0.6445 - val_loss: 1.1126 - val_accuracy: 0.6484\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9512 - accuracy: 0.6680 - val_loss: 1.1334 - val_accuracy: 0.6562\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9155 - accuracy: 0.6855 - val_loss: 1.1106 - val_accuracy: 0.6602\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9067 - accuracy: 0.6953 - val_loss: 1.0662 - val_accuracy: 0.6602\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.8481 - accuracy: 0.6992 - val_loss: 1.0930 - val_accuracy: 0.6660\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.8149 - accuracy: 0.7090 - val_loss: 1.1159 - val_accuracy: 0.6719\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8618 - accuracy: 0.6895 - val_loss: 1.0462 - val_accuracy: 0.6738\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8563 - accuracy: 0.7090 - val_loss: 1.0741 - val_accuracy: 0.6797\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8136 - accuracy: 0.7051 - val_loss: 1.0546 - val_accuracy: 0.6895\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.7697 - accuracy: 0.7266 - val_loss: 1.1174 - val_accuracy: 0.6797\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7676 - accuracy: 0.7266 - val_loss: 1.1352 - val_accuracy: 0.6836\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7367 - accuracy: 0.7168 - val_loss: 1.0509 - val_accuracy: 0.6914\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7028 - accuracy: 0.7578 - val_loss: 1.1350 - val_accuracy: 0.7129\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7044 - accuracy: 0.7637 - val_loss: 1.1353 - val_accuracy: 0.7012\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7515 - accuracy: 0.7480 - val_loss: 1.0771 - val_accuracy: 0.6816\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6990 - accuracy: 0.7520 - val_loss: 1.1170 - val_accuracy: 0.6914\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6372 - accuracy: 0.7500 - val_loss: 1.1088 - val_accuracy: 0.6914\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6012 - accuracy: 0.7832 - val_loss: 1.1389 - val_accuracy: 0.7012\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5739 - accuracy: 0.7969 - val_loss: 1.1709 - val_accuracy: 0.7012\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5889 - accuracy: 0.7871 - val_loss: 1.0345 - val_accuracy: 0.7051\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5376 - accuracy: 0.8086 - val_loss: 1.1921 - val_accuracy: 0.6895\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5703 - accuracy: 0.8047 - val_loss: 1.1203 - val_accuracy: 0.7090\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5134 - accuracy: 0.8242 - val_loss: 1.1616 - val_accuracy: 0.7129\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5241 - accuracy: 0.8145 - val_loss: 1.1463 - val_accuracy: 0.7168\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.4887 - accuracy: 0.8086 - val_loss: 1.1391 - val_accuracy: 0.6934\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4501 - accuracy: 0.8262 - val_loss: 1.3326 - val_accuracy: 0.6934\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4799 - accuracy: 0.8164 - val_loss: 1.2742 - val_accuracy: 0.7012\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4681 - accuracy: 0.8477 - val_loss: 1.2548 - val_accuracy: 0.6875\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4038 - accuracy: 0.8594 - val_loss: 1.4422 - val_accuracy: 0.7188\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4211 - accuracy: 0.8477 - val_loss: 1.2931 - val_accuracy: 0.7031\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4048 - accuracy: 0.8535 - val_loss: 1.1988 - val_accuracy: 0.6914\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3961 - accuracy: 0.8594 - val_loss: 1.2408 - val_accuracy: 0.7012\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3659 - accuracy: 0.8789 - val_loss: 1.4032 - val_accuracy: 0.7148\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3446 - accuracy: 0.8906 - val_loss: 1.4799 - val_accuracy: 0.7012\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3789 - accuracy: 0.8574 - val_loss: 1.3454 - val_accuracy: 0.7012\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3599 - accuracy: 0.8672 - val_loss: 1.2723 - val_accuracy: 0.7012\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "result = model_test.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    steps_per_epoch=16,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val,Y_val),\n",
    "    callbacks=[EarlyStopping(patience=16, verbose=1)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ab367c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "658dacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 2.2935 - accuracy: 0.1777 - val_loss: 2.0550 - val_accuracy: 0.3008\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 2.1229 - accuracy: 0.2500 - val_loss: 2.0457 - val_accuracy: 0.3008\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 2.0147 - accuracy: 0.2695 - val_loss: 1.8402 - val_accuracy: 0.3008\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.9801 - accuracy: 0.2793 - val_loss: 1.7728 - val_accuracy: 0.4512\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.8463 - accuracy: 0.3242 - val_loss: 1.6641 - val_accuracy: 0.4902\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.7837 - accuracy: 0.3379 - val_loss: 1.5469 - val_accuracy: 0.5020\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.7014 - accuracy: 0.3750 - val_loss: 1.5643 - val_accuracy: 0.5234\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.7009 - accuracy: 0.3906 - val_loss: 1.5221 - val_accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.5787 - accuracy: 0.4316 - val_loss: 1.4444 - val_accuracy: 0.5410\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.5858 - accuracy: 0.4473 - val_loss: 1.4497 - val_accuracy: 0.5527\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.5369 - accuracy: 0.4512 - val_loss: 1.3987 - val_accuracy: 0.5625\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.5289 - accuracy: 0.4688 - val_loss: 1.4284 - val_accuracy: 0.5703\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.4433 - accuracy: 0.4824 - val_loss: 1.3254 - val_accuracy: 0.5684\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.4462 - accuracy: 0.4961 - val_loss: 1.3450 - val_accuracy: 0.5898\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.4390 - accuracy: 0.5039 - val_loss: 1.3332 - val_accuracy: 0.5996\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.4271 - accuracy: 0.4980 - val_loss: 1.3138 - val_accuracy: 0.5957\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.3442 - accuracy: 0.5195 - val_loss: 1.2889 - val_accuracy: 0.5996\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3432 - accuracy: 0.5039 - val_loss: 1.2821 - val_accuracy: 0.6133\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.2969 - accuracy: 0.5156 - val_loss: 1.2547 - val_accuracy: 0.6152\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.2894 - accuracy: 0.5332 - val_loss: 1.2592 - val_accuracy: 0.6191\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3022 - accuracy: 0.5371 - val_loss: 1.2830 - val_accuracy: 0.6230\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.2379 - accuracy: 0.5547 - val_loss: 1.2651 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.2440 - accuracy: 0.5605 - val_loss: 1.2266 - val_accuracy: 0.6270\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.2360 - accuracy: 0.5586 - val_loss: 1.2250 - val_accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.1857 - accuracy: 0.6055 - val_loss: 1.2386 - val_accuracy: 0.6289\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.2062 - accuracy: 0.5645 - val_loss: 1.2140 - val_accuracy: 0.6270\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.1188 - accuracy: 0.6074 - val_loss: 1.2039 - val_accuracy: 0.6289\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.1748 - accuracy: 0.5703 - val_loss: 1.1986 - val_accuracy: 0.6348\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.2179 - accuracy: 0.5879 - val_loss: 1.1988 - val_accuracy: 0.6289\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.1229 - accuracy: 0.5703 - val_loss: 1.2025 - val_accuracy: 0.6230\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.0950 - accuracy: 0.6387 - val_loss: 1.1913 - val_accuracy: 0.6309\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.1288 - accuracy: 0.6016 - val_loss: 1.1768 - val_accuracy: 0.6328\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.1018 - accuracy: 0.5977 - val_loss: 1.2039 - val_accuracy: 0.6289\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.0557 - accuracy: 0.6172 - val_loss: 1.2114 - val_accuracy: 0.6309\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.0315 - accuracy: 0.6191 - val_loss: 1.1967 - val_accuracy: 0.6270\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.0073 - accuracy: 0.6367 - val_loss: 1.1852 - val_accuracy: 0.6328\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.0623 - accuracy: 0.6074 - val_loss: 1.2205 - val_accuracy: 0.6250\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.0093 - accuracy: 0.6270 - val_loss: 1.1985 - val_accuracy: 0.6309\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9712 - accuracy: 0.6230 - val_loss: 1.1670 - val_accuracy: 0.6367\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.9978 - accuracy: 0.6211 - val_loss: 1.1836 - val_accuracy: 0.6426\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9523 - accuracy: 0.6191 - val_loss: 1.2153 - val_accuracy: 0.6367\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.0245 - accuracy: 0.6133 - val_loss: 1.1784 - val_accuracy: 0.6367\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9125 - accuracy: 0.6504 - val_loss: 1.2181 - val_accuracy: 0.6367\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9704 - accuracy: 0.6289 - val_loss: 1.1774 - val_accuracy: 0.6367\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.9066 - accuracy: 0.6484 - val_loss: 1.2386 - val_accuracy: 0.6348\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9422 - accuracy: 0.6289 - val_loss: 1.2102 - val_accuracy: 0.6465\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.9363 - accuracy: 0.6387 - val_loss: 1.2086 - val_accuracy: 0.6387\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8980 - accuracy: 0.6523 - val_loss: 1.1876 - val_accuracy: 0.6348\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.9642 - accuracy: 0.6309 - val_loss: 1.2245 - val_accuracy: 0.6406\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9070 - accuracy: 0.6504 - val_loss: 1.1954 - val_accuracy: 0.6465\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8869 - accuracy: 0.6445 - val_loss: 1.1592 - val_accuracy: 0.6328\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.8890 - accuracy: 0.6504 - val_loss: 1.1807 - val_accuracy: 0.6406\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.8685 - accuracy: 0.6523 - val_loss: 1.2290 - val_accuracy: 0.6426\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.8473 - accuracy: 0.6602 - val_loss: 1.2030 - val_accuracy: 0.6426\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.8724 - accuracy: 0.6855 - val_loss: 1.1963 - val_accuracy: 0.6484\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.8014 - accuracy: 0.6602 - val_loss: 1.3029 - val_accuracy: 0.6445\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.8319 - accuracy: 0.6582 - val_loss: 1.2920 - val_accuracy: 0.6523\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.8525 - accuracy: 0.6621 - val_loss: 1.2682 - val_accuracy: 0.6484\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.8333 - accuracy: 0.6523 - val_loss: 1.2524 - val_accuracy: 0.6465\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8542 - accuracy: 0.6621 - val_loss: 1.2122 - val_accuracy: 0.6230\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.8376 - accuracy: 0.6543 - val_loss: 1.2317 - val_accuracy: 0.6367\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.8283 - accuracy: 0.6660 - val_loss: 1.2569 - val_accuracy: 0.6230\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7802 - accuracy: 0.6816 - val_loss: 1.3189 - val_accuracy: 0.6406\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.8341 - accuracy: 0.6582 - val_loss: 1.2788 - val_accuracy: 0.6309\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.8265 - accuracy: 0.6875 - val_loss: 1.2155 - val_accuracy: 0.6387\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.7979 - accuracy: 0.6895 - val_loss: 1.2507 - val_accuracy: 0.6465\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8122 - accuracy: 0.6641 - val_loss: 1.3008 - val_accuracy: 0.6523\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.7671 - accuracy: 0.6914 - val_loss: 1.3473 - val_accuracy: 0.6562\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.7661 - accuracy: 0.6973 - val_loss: 1.4337 - val_accuracy: 0.6719\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7470 - accuracy: 0.7031 - val_loss: 1.3324 - val_accuracy: 0.6367\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7474 - accuracy: 0.6855 - val_loss: 1.3161 - val_accuracy: 0.6426\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.7406 - accuracy: 0.7070 - val_loss: 1.4060 - val_accuracy: 0.6445\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.7922 - accuracy: 0.6621 - val_loss: 1.4132 - val_accuracy: 0.6387\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7344 - accuracy: 0.7129 - val_loss: 1.3144 - val_accuracy: 0.6328\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7528 - accuracy: 0.6953 - val_loss: 1.4133 - val_accuracy: 0.6523\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.8333 - accuracy: 0.6543 - val_loss: 1.5375 - val_accuracy: 0.6504\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7717 - accuracy: 0.6855 - val_loss: 1.2594 - val_accuracy: 0.6426\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7355 - accuracy: 0.6836 - val_loss: 1.2493 - val_accuracy: 0.6465\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.7493 - accuracy: 0.7188 - val_loss: 1.3483 - val_accuracy: 0.6504\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.7173 - accuracy: 0.7031 - val_loss: 1.3144 - val_accuracy: 0.6348\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.7354 - accuracy: 0.7207 - val_loss: 1.3674 - val_accuracy: 0.6562\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.7124 - accuracy: 0.6953 - val_loss: 1.3256 - val_accuracy: 0.6465\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7323 - accuracy: 0.6895 - val_loss: 1.2978 - val_accuracy: 0.6504\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7188 - accuracy: 0.7031 - val_loss: 1.4153 - val_accuracy: 0.6426\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7346 - accuracy: 0.6738 - val_loss: 1.3784 - val_accuracy: 0.6504\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6980 - accuracy: 0.7090 - val_loss: 1.4168 - val_accuracy: 0.6445\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7006 - accuracy: 0.7188 - val_loss: 1.4552 - val_accuracy: 0.6484\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6869 - accuracy: 0.7168 - val_loss: 1.5286 - val_accuracy: 0.6328\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7269 - accuracy: 0.7051 - val_loss: 1.5145 - val_accuracy: 0.6426\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6735 - accuracy: 0.7383 - val_loss: 1.3944 - val_accuracy: 0.6367\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.6787 - accuracy: 0.7246 - val_loss: 1.4434 - val_accuracy: 0.6406\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6676 - accuracy: 0.7383 - val_loss: 1.4357 - val_accuracy: 0.6621\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7167 - accuracy: 0.7148 - val_loss: 1.5034 - val_accuracy: 0.6484\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7252 - accuracy: 0.7188 - val_loss: 1.4429 - val_accuracy: 0.6367\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.7327 - accuracy: 0.6855 - val_loss: 1.3377 - val_accuracy: 0.6426\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.6958 - accuracy: 0.7305 - val_loss: 1.4185 - val_accuracy: 0.6426\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.6711 - accuracy: 0.7188 - val_loss: 1.4355 - val_accuracy: 0.6465\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.6865 - accuracy: 0.7324 - val_loss: 1.4991 - val_accuracy: 0.6426\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.7271 - accuracy: 0.7070 - val_loss: 1.2929 - val_accuracy: 0.6426\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.6583 - accuracy: 0.7461 - val_loss: 1.3729 - val_accuracy: 0.6465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2470ad6ffa0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.fit(\n",
    "          X_train,\n",
    "          Y_train,\n",
    "          epochs=100,\n",
    "          validation_data=(X_val,Y_val),\n",
    "          validation_freq=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a4b2e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 2.0334 - accuracy: 0.2930 - val_loss: 1.7656 - val_accuracy: 0.5547\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.7534 - accuracy: 0.4062 - val_loss: 1.5005 - val_accuracy: 0.5039\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 1.4982 - accuracy: 0.4688 - val_loss: 1.3698 - val_accuracy: 0.5859\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.3902 - accuracy: 0.5078 - val_loss: 1.3021 - val_accuracy: 0.5781\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.2347 - accuracy: 0.5312 - val_loss: 1.2692 - val_accuracy: 0.5977\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1972 - accuracy: 0.5430 - val_loss: 1.3046 - val_accuracy: 0.6016\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1376 - accuracy: 0.5938 - val_loss: 1.2373 - val_accuracy: 0.6250\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.0798 - accuracy: 0.6055 - val_loss: 1.2059 - val_accuracy: 0.6250\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0039 - accuracy: 0.6484 - val_loss: 1.1920 - val_accuracy: 0.6562\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9450 - accuracy: 0.6367 - val_loss: 1.1731 - val_accuracy: 0.6562\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9140 - accuracy: 0.6992 - val_loss: 1.2376 - val_accuracy: 0.6406\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.8536 - accuracy: 0.6992 - val_loss: 1.2636 - val_accuracy: 0.6523\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7734 - accuracy: 0.6992 - val_loss: 1.3172 - val_accuracy: 0.6797\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6617 - accuracy: 0.7734 - val_loss: 1.3030 - val_accuracy: 0.6719\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6536 - accuracy: 0.7734 - val_loss: 1.3273 - val_accuracy: 0.6523\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.6110 - accuracy: 0.7891 - val_loss: 1.2553 - val_accuracy: 0.6719\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.5805 - accuracy: 0.8008 - val_loss: 1.3849 - val_accuracy: 0.6562\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.5382 - accuracy: 0.8164 - val_loss: 1.2573 - val_accuracy: 0.6914\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5396 - accuracy: 0.7773 - val_loss: 1.5437 - val_accuracy: 0.6641\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4023 - accuracy: 0.8438 - val_loss: 1.7939 - val_accuracy: 0.6602\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.4745 - accuracy: 0.8633 - val_loss: 1.4226 - val_accuracy: 0.6602\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.3520 - accuracy: 0.8672 - val_loss: 1.5635 - val_accuracy: 0.6719\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4010 - accuracy: 0.8477 - val_loss: 1.5947 - val_accuracy: 0.6445\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.3056 - accuracy: 0.8789 - val_loss: 1.7077 - val_accuracy: 0.6719\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.3168 - accuracy: 0.8945 - val_loss: 1.6133 - val_accuracy: 0.6758\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2743 - accuracy: 0.8906 - val_loss: 1.7614 - val_accuracy: 0.6641\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.3042 - accuracy: 0.8828 - val_loss: 1.9596 - val_accuracy: 0.6641\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.2455 - accuracy: 0.9102 - val_loss: 1.7797 - val_accuracy: 0.6562\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.2540 - accuracy: 0.9141 - val_loss: 1.9615 - val_accuracy: 0.6680\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.1923 - accuracy: 0.9375 - val_loss: 1.9449 - val_accuracy: 0.7031\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1748 - accuracy: 0.9453 - val_loss: 1.9848 - val_accuracy: 0.6992\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1555 - accuracy: 0.9453 - val_loss: 2.1554 - val_accuracy: 0.6992\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.1848 - accuracy: 0.9297 - val_loss: 2.3051 - val_accuracy: 0.6836\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.1908 - accuracy: 0.9375 - val_loss: 2.0498 - val_accuracy: 0.6602\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.1567 - accuracy: 0.9531 - val_loss: 1.9635 - val_accuracy: 0.6953\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.1601 - accuracy: 0.9453 - val_loss: 2.2415 - val_accuracy: 0.6836\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.1669 - accuracy: 0.9453 - val_loss: 2.1282 - val_accuracy: 0.6719\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1043 - accuracy: 0.9531 - val_loss: 2.1130 - val_accuracy: 0.6758\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.1419 - accuracy: 0.9531 - val_loss: 2.1135 - val_accuracy: 0.6992\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.1822 - accuracy: 0.9297 - val_loss: 2.0866 - val_accuracy: 0.6953\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.1363 - accuracy: 0.9492 - val_loss: 2.2355 - val_accuracy: 0.6719\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0904 - accuracy: 0.9766 - val_loss: 2.4679 - val_accuracy: 0.6914\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.1102 - accuracy: 0.9570 - val_loss: 2.5446 - val_accuracy: 0.6875\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0669 - accuracy: 0.9844 - val_loss: 2.5284 - val_accuracy: 0.6875\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.1079 - accuracy: 0.9688 - val_loss: 2.3330 - val_accuracy: 0.6719\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0782 - accuracy: 0.9766 - val_loss: 2.4055 - val_accuracy: 0.6641\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0832 - accuracy: 0.9727 - val_loss: 2.4083 - val_accuracy: 0.6992\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0696 - accuracy: 0.9805 - val_loss: 2.3701 - val_accuracy: 0.6953\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0448 - accuracy: 0.9883 - val_loss: 2.4133 - val_accuracy: 0.6992\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0792 - accuracy: 0.9844 - val_loss: 2.3210 - val_accuracy: 0.6836\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0738 - accuracy: 0.9688 - val_loss: 1.9985 - val_accuracy: 0.6797\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0541 - accuracy: 0.9766 - val_loss: 2.1217 - val_accuracy: 0.6719\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0456 - accuracy: 0.9766 - val_loss: 2.1402 - val_accuracy: 0.7031\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0296 - accuracy: 0.9922 - val_loss: 2.4012 - val_accuracy: 0.6875\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0587 - accuracy: 0.9766 - val_loss: 2.2315 - val_accuracy: 0.6953\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 2.5683 - val_accuracy: 0.7031\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0417 - accuracy: 0.9844 - val_loss: 2.5729 - val_accuracy: 0.6875\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0537 - accuracy: 0.9844 - val_loss: 2.2737 - val_accuracy: 0.6953\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0560 - accuracy: 0.9844 - val_loss: 2.1649 - val_accuracy: 0.6992\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0546 - accuracy: 0.9883 - val_loss: 2.2024 - val_accuracy: 0.7031\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0402 - accuracy: 0.9844 - val_loss: 2.3059 - val_accuracy: 0.6953\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5439 - val_accuracy: 0.6875\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0643 - accuracy: 0.9766 - val_loss: 2.5848 - val_accuracy: 0.6758\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 2.5017 - val_accuracy: 0.6719\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0704 - accuracy: 0.9688 - val_loss: 2.4704 - val_accuracy: 0.6758\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0379 - accuracy: 0.9844 - val_loss: 2.4129 - val_accuracy: 0.6875\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 2.4196 - val_accuracy: 0.6953\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 2.5100 - val_accuracy: 0.6953\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 2.4100 - val_accuracy: 0.6797\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0629 - accuracy: 0.9805 - val_loss: 2.3394 - val_accuracy: 0.6797\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0986 - accuracy: 0.9688 - val_loss: 2.0738 - val_accuracy: 0.6875\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.0478 - val_accuracy: 0.6797\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0310 - accuracy: 0.9844 - val_loss: 2.1949 - val_accuracy: 0.7031\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0387 - accuracy: 0.9922 - val_loss: 2.4905 - val_accuracy: 0.7031\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 2.7778 - val_accuracy: 0.6875\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0305 - accuracy: 0.9883 - val_loss: 2.9467 - val_accuracy: 0.7070\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 2.8259 - val_accuracy: 0.6914\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 2.9902 - val_accuracy: 0.6914\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0531 - accuracy: 0.9805 - val_loss: 2.6998 - val_accuracy: 0.6953\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 2.6447 - val_accuracy: 0.6914\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0409 - accuracy: 0.9844 - val_loss: 2.7559 - val_accuracy: 0.6992\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.8383 - val_accuracy: 0.7070\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.9991 - val_accuracy: 0.7109\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0102 - accuracy: 0.9961 - val_loss: 3.2262 - val_accuracy: 0.6992\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0139 - accuracy: 0.9922 - val_loss: 3.2327 - val_accuracy: 0.6953\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0435 - accuracy: 0.9844 - val_loss: 3.1479 - val_accuracy: 0.7031\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0442 - accuracy: 0.9883 - val_loss: 2.8950 - val_accuracy: 0.7070\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 2.6268 - val_accuracy: 0.6953\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0404 - accuracy: 0.9844 - val_loss: 2.7775 - val_accuracy: 0.6680\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0437 - accuracy: 0.9844 - val_loss: 3.0548 - val_accuracy: 0.6992\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 3.2022 - val_accuracy: 0.6797\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0552 - accuracy: 0.9766 - val_loss: 2.8530 - val_accuracy: 0.6797\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 2.7658 - val_accuracy: 0.6758\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0307 - accuracy: 0.9922 - val_loss: 2.8008 - val_accuracy: 0.6797\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0344 - accuracy: 0.9922 - val_loss: 3.2677 - val_accuracy: 0.6836\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0741 - accuracy: 0.9883 - val_loss: 2.9295 - val_accuracy: 0.7031\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0267 - accuracy: 0.9844 - val_loss: 2.8662 - val_accuracy: 0.6797\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0622 - accuracy: 0.9883 - val_loss: 2.8162 - val_accuracy: 0.6875\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0322 - accuracy: 0.9883 - val_loss: 2.9613 - val_accuracy: 0.6836\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0795 - accuracy: 0.9766 - val_loss: 2.4368 - val_accuracy: 0.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ee74c370>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.fit(\n",
    "          X_train,\n",
    "          Y_train,\n",
    "          epochs=100,\n",
    "          validation_data=(X_val,Y_val),\n",
    "          validation_freq=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a6e03c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 22, 22, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 22, 22, 96)       384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 10, 10, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 10, 10, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 10, 10, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 4, 4, 384)         885120    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 4, 4, 384)        1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 4, 4, 384)         1327488   \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 4, 4, 384)        1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 4, 256)         884992    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 9)                 36873     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,623,561\n",
      "Trainable params: 21,620,809\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# AlexNet\n",
    "\n",
    "model_alex = Sequential([\n",
    "    layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(TARGET_HEIGHT,TARGET_WIDTH,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "model_test.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'])\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3459f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, (3,3),input_shape=(TARGET_HEIGHT,TARGET_WIDTH,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(9, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3bf4ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 94, 94, 10)        280       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 47, 47, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 45, 45, 32)        2912      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 22, 22, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 20, 20, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 512)               3277312   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 9)                 4617      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,303,617\n",
      "Trainable params: 3,303,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b277f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 17s 11ms/step - loss: 1.4575 - accuracy: 0.5150 - val_loss: 1.3532 - val_accuracy: 0.6214\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.0450 - accuracy: 0.6450 - val_loss: 1.2506 - val_accuracy: 0.6429\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7835 - accuracy: 0.7625 - val_loss: 1.1258 - val_accuracy: 0.6500\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5652 - accuracy: 0.8000 - val_loss: 1.3968 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3342 - accuracy: 0.8850 - val_loss: 1.1229 - val_accuracy: 0.7214\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1816 - accuracy: 0.9375 - val_loss: 1.2850 - val_accuracy: 0.6857\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1442 - accuracy: 0.9500 - val_loss: 0.9910 - val_accuracy: 0.7071\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0962 - accuracy: 0.9725 - val_loss: 1.2145 - val_accuracy: 0.7643\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9900 - val_loss: 1.2604 - val_accuracy: 0.7286\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 1.4489 - val_accuracy: 0.7286\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1495 - val_accuracy: 0.7786\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2414 - val_accuracy: 0.7786\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.4323e-04 - accuracy: 1.0000 - val_loss: 1.2715 - val_accuracy: 0.7786\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6.1381e-04 - accuracy: 1.0000 - val_loss: 1.3096 - val_accuracy: 0.7643\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.0976e-04 - accuracy: 1.0000 - val_loss: 1.3368 - val_accuracy: 0.7714\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 4.3916e-04 - accuracy: 1.0000 - val_loss: 1.3543 - val_accuracy: 0.7714\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3.3628e-04 - accuracy: 1.0000 - val_loss: 1.3786 - val_accuracy: 0.7714\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.8474e-04 - accuracy: 1.0000 - val_loss: 1.4036 - val_accuracy: 0.7643\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.5359e-04 - accuracy: 1.0000 - val_loss: 1.4195 - val_accuracy: 0.7714\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.1742e-04 - accuracy: 1.0000 - val_loss: 1.4331 - val_accuracy: 0.7714\n"
     ]
    }
   ],
   "source": [
    "#Proprietatry\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "result = model.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val,Y_val),\n",
    "    callbacks=[EarlyStopping(patience=16, verbose=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f330fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47db705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 2.1764 - accuracy: 0.2275 - val_loss: 2.1908 - val_accuracy: 0.2571\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.8851 - accuracy: 0.3450 - val_loss: 2.1787 - val_accuracy: 0.2571\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.6016 - accuracy: 0.4600 - val_loss: 2.1633 - val_accuracy: 0.2571\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.5415 - accuracy: 0.4750 - val_loss: 2.1474 - val_accuracy: 0.2571\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3983 - accuracy: 0.5275 - val_loss: 2.1280 - val_accuracy: 0.2571\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.2879 - accuracy: 0.5475 - val_loss: 2.1096 - val_accuracy: 0.2571\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2478 - accuracy: 0.5775 - val_loss: 2.0901 - val_accuracy: 0.2571\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1433 - accuracy: 0.6475 - val_loss: 2.0638 - val_accuracy: 0.2571\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0329 - accuracy: 0.6950 - val_loss: 2.0444 - val_accuracy: 0.2571\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.9939 - accuracy: 0.6725 - val_loss: 2.0249 - val_accuracy: 0.2571\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.9667 - accuracy: 0.7050 - val_loss: 2.0121 - val_accuracy: 0.2571\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9163 - accuracy: 0.7325 - val_loss: 1.9889 - val_accuracy: 0.2571\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.8611 - accuracy: 0.7350 - val_loss: 1.9833 - val_accuracy: 0.2571\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.8270 - accuracy: 0.7650 - val_loss: 1.9749 - val_accuracy: 0.2857\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.8049 - accuracy: 0.7500 - val_loss: 1.9579 - val_accuracy: 0.4143\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7255 - accuracy: 0.7775 - val_loss: 1.9544 - val_accuracy: 0.3571\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6620 - accuracy: 0.8100 - val_loss: 1.9393 - val_accuracy: 0.4071\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.6448 - accuracy: 0.8000 - val_loss: 1.9262 - val_accuracy: 0.4071\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6151 - accuracy: 0.8225 - val_loss: 1.9194 - val_accuracy: 0.4143\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.5850 - accuracy: 0.8350 - val_loss: 1.9372 - val_accuracy: 0.4214\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5588 - accuracy: 0.8400 - val_loss: 1.9173 - val_accuracy: 0.4214\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5157 - accuracy: 0.8550 - val_loss: 1.9167 - val_accuracy: 0.4286\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5060 - accuracy: 0.8525 - val_loss: 1.9126 - val_accuracy: 0.4286\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5303 - accuracy: 0.8475 - val_loss: 1.8982 - val_accuracy: 0.4357\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4295 - accuracy: 0.8775 - val_loss: 1.8842 - val_accuracy: 0.4429\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4011 - accuracy: 0.8950 - val_loss: 1.8998 - val_accuracy: 0.4571\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.4113 - accuracy: 0.8800 - val_loss: 1.8962 - val_accuracy: 0.4500\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.3972 - accuracy: 0.8975 - val_loss: 1.8137 - val_accuracy: 0.4786\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3799 - accuracy: 0.9025 - val_loss: 1.8286 - val_accuracy: 0.4571\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3529 - accuracy: 0.9025 - val_loss: 1.8221 - val_accuracy: 0.4571\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.2822 - accuracy: 0.9250 - val_loss: 1.7988 - val_accuracy: 0.4643\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3196 - accuracy: 0.9150 - val_loss: 1.7632 - val_accuracy: 0.4571\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2970 - accuracy: 0.9200 - val_loss: 1.7610 - val_accuracy: 0.4571\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.2689 - accuracy: 0.9375 - val_loss: 1.7122 - val_accuracy: 0.4643\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2256 - accuracy: 0.9625 - val_loss: 1.6900 - val_accuracy: 0.4714\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.2519 - accuracy: 0.9525 - val_loss: 1.6315 - val_accuracy: 0.4857\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2294 - accuracy: 0.9575 - val_loss: 1.4532 - val_accuracy: 0.5286\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.2241 - accuracy: 0.9475 - val_loss: 1.5635 - val_accuracy: 0.5357\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1909 - accuracy: 0.9675 - val_loss: 1.4898 - val_accuracy: 0.5571\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1883 - accuracy: 0.9525 - val_loss: 1.4368 - val_accuracy: 0.5571\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1784 - accuracy: 0.9625 - val_loss: 1.4173 - val_accuracy: 0.5714\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1561 - accuracy: 0.9775 - val_loss: 1.4077 - val_accuracy: 0.5643\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1566 - accuracy: 0.9750 - val_loss: 1.2846 - val_accuracy: 0.5929\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1448 - accuracy: 0.9800 - val_loss: 1.3158 - val_accuracy: 0.5786\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1556 - accuracy: 0.9725 - val_loss: 1.1971 - val_accuracy: 0.5929\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1557 - accuracy: 0.9650 - val_loss: 1.2751 - val_accuracy: 0.5714\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1330 - accuracy: 0.9825 - val_loss: 1.1733 - val_accuracy: 0.6000\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1171 - accuracy: 0.9825 - val_loss: 1.1349 - val_accuracy: 0.6286\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1069 - accuracy: 0.9850 - val_loss: 1.0821 - val_accuracy: 0.6357\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1094 - accuracy: 0.9925 - val_loss: 1.0203 - val_accuracy: 0.6643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2503d0b80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AlexNet\n",
    "\n",
    "model_test.fit(\n",
    "          X_train,\n",
    "          Y_train,\n",
    "          epochs=50,\n",
    "          validation_data=(X_val,Y_val),\n",
    "          validation_freq=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa491e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils  import to_categorical\n",
    "\n",
    "Y_train_ohe = to_categorical(Y_train, 9)\n",
    "Y_val_ohe = to_categorical(Y_val, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c667ee9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 9) and (None, 1, 1, 2048) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27616/4251713702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m inception_model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 9) and (None, 1, 1, 2048) are incompatible\n"
     ]
    }
   ],
   "source": [
    "inception_model.fit(\n",
    "          X_train, \n",
    "          Y_train,\n",
    "          epochs=50,\n",
    "          validation_data=(X_val,Y_val),\n",
    "          validation_freq=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b9b74f9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"inception_v3\" is incompatible with the layer: expected shape=(None, 299, 299, 3), found shape=(None, 96, 96, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27616/4251713702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m inception_model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"inception_v3\" is incompatible with the layer: expected shape=(None, 299, 299, 3), found shape=(None, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "inception_model.fit(\n",
    "          X_train, \n",
    "          Y_train,\n",
    "          epochs=50,\n",
    "          validation_data=(X_val,Y_val),\n",
    "          validation_freq=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ca0563b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 9, 9) and (None, 3, 3, 512) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27616/781415085.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m vgg16_model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mY_train_ohe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_val_ohe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 9, 9) and (None, 3, 3, 512) are incompatible\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.fit(\n",
    "          X_train, \n",
    "          Y_train_ohe,\n",
    "          epochs=50,\n",
    "          validation_data=(X_val,Y_val_ohe),\n",
    "          validation_freq=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80fb7d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f44d3cf730>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABL/ElEQVR4nO3deXhU5d3/8fdkh5AEQiAkZGXfEcK+uKCCKLgrLgU3bKlbEetCfVpb26eotdRaBTcQferCr7KUKqKxssm+BEHZCZiQhZAAWQhZ5/z+OCQQSEImmcnJTD6v65qLYXLOzHdyCPPJfb73fWyGYRiIiIiIWMTL6gJERESkeVMYEREREUspjIiIiIilFEZERETEUgojIiIiYimFEREREbGUwoiIiIhYSmFERERELOVjdQF1YbfbSU9PJygoCJvNZnU5IiIiUgeGYZCfn09kZCReXjWPf7hFGElPTyc6OtrqMkRERKQeUlNTiYqKqvHrbhFGgoKCAPPNBAcHW1yNiIiI1EVeXh7R0dGVn+M1cYswUnFqJjg4WGFERETEzVyqxUINrCIiImIphRERERGxlMKIiIiIWEphRERERCylMCIiIiKWUhgRERERSymMiIiIiKUURkRERMRSCiMiIiJiKYfDyJo1a5g4cSKRkZHYbDaWLl16yX1Wr15NQkICAQEBdOrUibfeeqs+tYqIiIgHcjiMnD59mv79+/PGG2/UafvDhw9z/fXXM3r0aJKSkvjNb37DE088waJFixwuVkRERDyPw9emGT9+POPHj6/z9m+99RYxMTG89tprAPTs2ZOtW7fy6quvcttttzn68iIiIuJhXH6hvA0bNjB27Ngqj40bN4558+ZRWlqKr6/vRfsUFxdTXFxc+fe8vDxXlykibiAj9wwLt6SSe6bU6lJEPM5tA6Po0zHEktd2eRjJzMwkPDy8ymPh4eGUlZWRnZ1NRETERfvMmjWLP/zhD64uTUTcRFZ+EXNWHuLjzSmUlNmtLkfEIw2IaeO5YQQuvnSwYRjVPl5h5syZzJgxo/LveXl5REdHu65AEWmScgqKeXtNMh9uOEJRqRlChsSFMji+jcWViXieru1bWfbaLg8jHTp0IDMzs8pjWVlZ+Pj40LZt22r38ff3x9/f39WliUgTdaqwhHfWJLNg/REKS8oBGBDTmqeu7c7ILm1r/EVGRNyTy8PI8OHD+c9//lPlsa+//ppBgwZV2y8iIs1XXlEp89YeZv53h8kvLgOgb8cQZlzbjSu7t1MIEfFQDoeRgoICDh48WPn3w4cPs2PHDkJDQ4mJiWHmzJmkpaXx4YcfAjBt2jTeeOMNZsyYwcMPP8yGDRuYN28en3zyifPehYi4tYLiMhasO8w7a5LJKzJDSI8OQcy4thvX9gpXCBHxcA6Hka1bt3LVVVdV/r2it+O+++5jwYIFZGRkkJKSUvn1+Ph4li9fzpNPPsmbb75JZGQkr7/+uqb1ighnSsr5cMMR3l6TzInTJQB0ad+KJ6/pxvg+HfDyUggRaQ5sRkU3aROWl5dHSEgIubm5BAcHW12OiNsqLbezJCmN3el59OgQxICYNnRp3wrvRv7QLyot5+NNKcxZdYjsAnMaf3xYINOv6cqEfpGNXo+IuEZdP78bZTaNiFir3G6wNCmN1789wE85hVW+1srfh/7RIQyMacOAmNZcFt2G0EA/l9RRXFbO/9uSyhsrD3Iszwwh0aEteGJMV24Z0BEfb10uS6Q5UhgR8WB2u8HnuzJ47Zv9JB8/DUDbQD/G9+3AwawCdh7NpaC4jHUHc1h3MKdyv7i2LRlwNpwMiG5Dj4ggfBsQFErL7Xy27ShvfHuQtFNnAIgMCeDxq7tye0JUg55bRNyfwoiIB7LbDb76MZO/fbOf/ccKAGjd0pefX96J+4bHEehv/uiXldvZf6yApNSTJKWcIinlJIeOn+ZITiFHcgpZkpQGgL+PF/2iQsyAEt2aATFt6BAScMk6ysrtLN2Rzuv/PUDKCXNEpn2QP4+N6cKkwdH4+3i76DsgIu5EPSMiHsQwDP67J4vZifvZnWFeRiEowIepozrx4Kg4ggIuPZ0+t7CUHUfNYFIRUCpmuJwvIiSgcuRkQExr+nQMIcDXDBfldoPPd6bz928OkJxtjsiEtfLjl1d24d6hMZXbiYhnq+vnt8KIiAcwDIM1B7KZnbif71NPARDo582Do+KZOqoTIS3rv6aP3W5wOOd0ZTBJSjnF3sw87Bf8z+HrbaNnRDD9o1qz6XBO5YhMm5a+/OKKzkwZHktLPw3GijQnCiMizcT6g2YI2frTSQBa+Hpz34g4fn55J5c1op4uLmNXWm5lQNmecqpyVkyF4AAfHh7diQdGxdPKXyFEpDnSbBoRD7flyAn++vU+NiafAMy+jp8Ni2XaFZ1pF+TayykE+vswrFNbhnUyL+lgGAZpp86QlHKK71NP0baVP/cMjSGkhVZZFpFLUxgRcTNJKSeZnbiftQeyAfDz9uKuIdE8elUXwoMv3VTqCjabjag2LYlq05KJ/SMtqUFE3JfCiIib+CEtl9mJ+/l2bxYAPl427hgUzWNjutCxdQuLqxMRqT+FEZEmbm9mHn9L3M9XPx4DwNvLxq0DOvL4mK7EtG1pcXUiIg2nMCLSRB3Myudv3xzgi50ZANhscFP/SH51TTfiwwItrk5ExHkURkSamIzcM7yyYh//3pFWOX32hr4RTL+mK13Dg6wtTkTEBRRGRJoIwzD4dEsqf/5iD/nF5iJjY3uF8+S13egZoSntIuK5FEZEmoDUE4U8t3hn5fVhBsS05g839qZfVGtrCxMRaQQKIyIWstsNPtxwhJdX7ONMaTkBvl48Pa4H94+Iw9vLZnV5IiKNQmFExCLJxwt4dtFOthwxV04dGh/Ky7f1I07NqSLSzCiMiDSycrvBvO+S+evX+ykusxPo581z1/fk3iExeGk0RESaIYURkUa0/1g+T3+2s/JidqO7hjHr1r5EtdF6ISLSfCmMiDSC0nI7b606xOvfHqC03CAowIffTujFHQlR2GwaDRGR5k1hRMTFfkjL5ZnPdrI7Iw+Aq3u0539v6UuHEGuuIyMi0tQojIi4SHFZOf/470Hmrj5Eud2gdUtf/nBjb27sH6nREBGR8yiMiLhAUspJnvlsJweyCgBzBdXf39ibdkH+FlcmItL0KIyIOFFRaTmzE/fz3tpk7AaEtfLjjzf1YXzfCKtLExFpshRGRJxk8+ETPLtoJ4ezTwNwy4CO/G5CL9oE+llcmYhI06YwItJAp4vLeGXFXj7Y8BMA4cH+/PmWvlzdM9ziykRE3IPCiEgDfHcgm+cW7+ToyTMA3DU4mpnX9ySkha/FlYmIuA+FEZF6yCsq5c9f7OHTLakAdGzdgpdu68voru0srkxExP0ojIg44MCxfBYnpfHZtqMczy8GYMrwWJ69rgeB/vpxEhGpD/3vKXIJ2QXFLNuRzpKkNHal5VY+Hte2JS/f1o+hndpaWJ2IiPtTGBGpRlFpOYm7j7EkKY3V+49TbjcA8PGycWX39tw6sCNX92yPv4+3xZWKiLg/hRGRs+x2gy1HTrB4exrLd2WQX1xW+bX+0a25dUBHJvSLoG0rLVwmIuJMCiPS7B06XsCS7WksSUoj7dSZysc7tm7BLQM6csvAjnRu18rCCkVEPJvCiDRLJ06X8PnOdBZtT+P71FOVj7fy9+GGvhHcMrAjQ+JC8fLSNWRERFxNYUSajeKycr7dk8Wi7Wms2pdF2dk+EG8vG5d3DePWgVFc2yucAF/1gYiINCaFEfFohmGw7aeTLE5K4/Pv08krOtcH0qdjMLcMiOLG/pG6gJ2IiIUURsQjZeYW8cnmFJbuSOOnnMLKxyNCArjpso7cOrAj3cKDLKxQREQqKIyIxzmeX8wNr68l53QJAC39vBnfJ4JbB3ZkWKe2eKsPRESkSVEYEY/zwrIfyDldQqewQJ64uitje4fT0k//1EVEmir9Dy0eZcUPGSzflYm3l43X7x5An44hVpckIiKX4GV1ASLOcqqwhP9Z+iMA067opCAiIuImFEbEY/zx8z1kFxTTuV0gj4/panU5IiJSRwoj4hFW7cti0faj2Gzwyu39tVaIiIgbURgRt1dQXMbzS34A4P4RcSTEtrG4IhERcYTCiLi9l7/cS9qpM0SHtuDpcd2tLkdERBykMCJubVNyDv+38ScAXrq1n6bwioi4IYURcVtFpeU8t3gXAHcNjmZklzCLKxIRkfpQGBG39bfE/RzOPk14sD+/uaGn1eWIiEg9KYyIW/o+9RTvrk0G4H9v7ktwgK/FFYmISH0pjIjbKSmz8+yindgNuLF/JNf0Cre6JBERaQCFEXE7c1YdZG9mPqGBfrwwsZfV5YiISAMpjIhb2ZeZz5srDwLw+xt707aVv8UViYhIQymMiNsoK7fzzGffU1pucE3PcCb2i7C6JBERcQKFEXEb89cd5vujuQQF+PC/t/TBZrNZXZKIiDiBwoi4hcPZp/nr1/sB+J8behIeHGBxRSIi4iwKI9Lk2e0Gzy7aSXGZnVFdwrhzULTVJYmIiBMpjEiT99HmFDYfPkFLP29m3dpXp2dERDyMwog0aWmnzvDS8j0APDOuO9GhLS2uSEREnE1hRJoswzCYuXgXp0vKGRTbhinD46wuSUREXEBhRJqsRdvTWLP/OH4+Xrx8ez+8vHR6RkTEE9UrjMyZM4f4+HgCAgJISEhg7dq1tW7/5ptv0rNnT1q0aEH37t358MMP61WsNB9Z+UX88fPdAEy/piud27WyuCIREXEVH0d3WLhwIdOnT2fOnDmMHDmSt99+m/Hjx7N7925iYmIu2n7u3LnMnDmTd999l8GDB7N582Yefvhh2rRpw8SJE53yJsTz/G7pj+SeKaVPx2B+PrqT1eWIiIgL2QzDMBzZYejQoQwcOJC5c+dWPtazZ09uvvlmZs2addH2I0aMYOTIkfzlL3+pfGz69Ols3bqV7777rk6vmZeXR0hICLm5uQQHBztSrrih5bsyeOSj7fh42Vj22Ch6ReqYi4i4o7p+fjt0mqakpIRt27YxduzYKo+PHTuW9evXV7tPcXExAQFVF6hq0aIFmzdvprS0tMZ98vLyqtykeTh5uoTf/fsHAH55ZWcFERGRZsChMJKdnU15eTnh4VUv2R4eHk5mZma1+4wbN4733nuPbdu2YRgGW7duZf78+ZSWlpKdnV3tPrNmzSIkJKTyFh2tRa6aiz9+vpvsghK6tm/FY2O6WF2OiIg0gno1sF646JRhGDUuRPXb3/6W8ePHM2zYMHx9fbnpppu4//77AfD29q52n5kzZ5Kbm1t5S01NrU+Z4mZW7s1icVIaNhu8fHs//H2q//chIiKexaEwEhYWhre390WjIFlZWReNllRo0aIF8+fPp7CwkCNHjpCSkkJcXBxBQUGEhYVVu4+/vz/BwcFVbuLZ8otK+c2SXQA8ODKegTFtLK5IREQai0NhxM/Pj4SEBBITE6s8npiYyIgRI2rd19fXl6ioKLy9vfn000+ZMGECXl5a5kRML325l4zcImJCW/Lrsd2tLkdERBqRw1N7Z8yYweTJkxk0aBDDhw/nnXfeISUlhWnTpgHmKZa0tLTKtUT279/P5s2bGTp0KCdPnmT27Nn88MMPfPDBB859J+K2NhzK4aNNKQC8dFtfWvjp9IyISHPicBiZNGkSOTk5vPjii2RkZNCnTx+WL19ObGwsABkZGaSkpFRuX15ezl//+lf27duHr68vV111FevXrycuLs5pb0Lc15mScp5bvBOAu4fEMKJz9afuRETEczm8zogVtM6I5/rfL3bz7trDdAgO4OsZlxMc4Gt1SSIi4iQuWWdExJl2pJ5i3neHAfjzrX0UREREmimFEbFEcVk5z3z2PXYDbr4skjE9qp+NJSIink9hRCzx9upk9h8roG2gH7+b2NvqckRExEIKI9LoisvKeX+deXrmtxN6ERroZ3FFIiJiJYURaXQrfsjkZGEpESEBTOgXYXU5IiJiMYURaXQVa4pMGhyNj7f+CYqINHf6JJBGdTArn82HT+BlM8OIiIiIwog0qo83mRc9HNMjnIiQFhZXIyIiTYHCiDSaotJyFm0/CsC9Q2MsrkZERJoKhRFpNF/szCD3TCkdW7fg8m7trC5HRESaCIURaTQfbzYbV+8eEo23l83iakREpKlQGJFGsS8zn20/ncTHy8adg9S4KiIi5yiMSKP4eNNPAFzTM5z2wQEWVyMiIk2Jwoi43JmSchYnpQFwjxpXRUTkAgoj4nL/2ZlOflEZMaEtGdUlzOpyRESkiVEYEZerWHH1riHReKlxVURELqAwIi71Y3ou36eewtfbxh0JalwVEZGLKYyIS318dlRkbO8OtAvyt7gaERFpihRGxGVOF5fx7x3pANw7RI2rIiJSPYURcZll36dTUFxGfFggwzu3tbocERFpohRGxGUqTtHcPSQam02NqyIiUj2FEXGJnUdPsSstFz9vL25X46qIiNRCYURcomJUZHzfDoQG+llcjYiINGUKI+J0+UWlLPvebFy9R42rIiJyCQoj4nRLd6RTWFJOl/atGBIfanU5IiLSxCmMiFMZhnFe42qMGldFROSSFEbEqZJST7EnIw8/Hy9uG9jR6nJERMQNKIyIU1WMikzoF0HrlmpcFRGRS1MYEafJPVPK5zvPrrg6VI2rIiJSNwoj4jRLth+lqNRO9/AgBsa0sbocERFxEwoj4hSGYfDxZvMUzT1D1bgqIiJ1pzAiTrHtp5PsP1ZAgK8XNw9Q46qIiNSdwog4xUdnG1cn9oskpIWvxdWIiIg7URiRBjt5uoQvdmUAcO+wWIurERERd6MwIg22aPtRSsrs9IoIpn9UiNXliIiIm1EYkQZR46qIiDSUwog0yKbDJ0g+fpqWft7cdFmk1eWIiIgbUhiRBqlYcfWmyyIJClDjqoiIOE5hROotp6CYL38wG1fvGaLGVRERqR+FEam3z7YdpbTcoF9UCH3VuCoiIvWkMCL1YrcbfFLRuDpE16EREZH6UxiRetmQnMORnEJa+fswsb8aV0VEpP4URqReKhpXbx4QSaC/j8XViIiIO1MYEYdl5Rfx1Y+ZgBpXRUSk4RRGxGH/2nqUMrvBgJjW9IoMtrocERFxcwoj4hC73eDTLWpcFRER51EYEYesPZhN6okzBAX4MKGfGldFRKThFEbEIR9v+gmA2wZG0cLP2+JqRETEEyiMSJ0dyyvimz1ZgHlRPBEREWdQGJE6W7gllXK7waDYNnQLD7K6HBER8RAKI1In5XaDT8+uuHrvMI2KiIiI8yiMSJ2s3p9Fem4RrVv6Mr5PhNXliIiIB1EYkTqpWHH1toFRBPiqcVVERJxHYUQuKf3UGb7dazau3q21RURExMkURuSSFm5JxW7A0PhQurRvZXU5IiLiYRRGpFZl5fbKFVfvHabr0IiIiPMpjEitvt2bxbG8YkID/RjXO9zqckRExAMpjEitPj47nfeOhCj8fdS4KiIizlevMDJnzhzi4+MJCAggISGBtWvX1rr9Rx99RP/+/WnZsiURERE88MAD5OTk1KtgaTypJwpZvf84oMZVERFxHYfDyMKFC5k+fTrPP/88SUlJjB49mvHjx5OSklLt9t999x1TpkzhoYce4scff+Rf//oXW7ZsYerUqQ0uXlxr4ZZUDANGdmlLXFig1eWIiIiHcjiMzJ49m4ceeoipU6fSs2dPXnvtNaKjo5k7d26122/cuJG4uDieeOIJ4uPjGTVqFL/4xS/YunVrg4sX1yktt7NwayoA9wxR46qIiLiOQ2GkpKSEbdu2MXbs2CqPjx07lvXr11e7z4gRIzh69CjLly/HMAyOHTvGZ599xg033FDj6xQXF5OXl1flJo3rs21HOZ5fTFgrf67tpcZVERFxHYfCSHZ2NuXl5YSHV/1wCg8PJzMzs9p9RowYwUcffcSkSZPw8/OjQ4cOtG7dmn/84x81vs6sWbMICQmpvEVHRztSpjTQ6v3H+e3SHwC4f0Qsfj7qcxYREdep16eMzWar8nfDMC56rMLu3bt54okn+N3vfse2bdtYsWIFhw8fZtq0aTU+/8yZM8nNza28paam1qdMqYeklJP88p/bKLMbTOwfySNXdrG6JBER8XA+jmwcFhaGt7f3RaMgWVlZF42WVJg1axYjR47k6aefBqBfv34EBgYyevRo/vSnPxERcfFF1/z9/fH393ekNHGCg1kFPLhgC4Ul5YzuGsZf7+iPl1f1IVNERMRZHBoZ8fPzIyEhgcTExCqPJyYmMmLEiGr3KSwsxMur6st4e5vrVRiG4cjLiwtl5J5hyrxNnCwspX9UCHN/lqDTMyIi0igc/rSZMWMG7733HvPnz2fPnj08+eSTpKSkVJ52mTlzJlOmTKncfuLEiSxevJi5c+eSnJzMunXreOKJJxgyZAiRkZHOeydSbydPlzB53mbSc4vo1C6Q+fcPppW/Q4NmIiIi9ebwJ86kSZPIycnhxRdfJCMjgz59+rB8+XJiY83pnxkZGVXWHLn//vvJz8/njTfe4KmnnqJ169aMGTOGl19+2XnvQuqtsKSMBz/YwsGsAjoEB/Dhg0No20qnyEREpPHYDDc4V5KXl0dISAi5ubkEBwdbXY7HKC23M/WDrazef5yQFr78a9pwuoUHWV2WiIh4iLp+fqspoJmy2w2e/tf3rN5/nABfL+bfP1hBRERELKEw0gwZhsEfv9jN0h3p+HjZmPuzBBJi21hdloiINFMKI83QnFWHeH/dEQD+ckc/rure3tqCRESkWVMYaWY+3ZzCX77aB8D/3NCTWwZEWVyRiIg0dwojzchXP2bymyW7APjllZ2ZOrqTxRWJiIgojDQbG5NzePyTJOwG3DkoimfGdbe6JBEREaAe64yI+/kxPZeHP9hKSZmda3uF8+db+tZ4LSGRJi8/E4pyra6i/lqEQqt2Vlch0qQojHi4n3JOc9/8LeQXlzEkPpR/3D0AH28NiImbOpAIH98Jht3qShrABt3GweCp0Plq8NLPo4jCiAfLyi9i8rzNZBcU0zMimPfuG0SAr7fVZYnUT+EJ+PejZhDxDwYvd/zvy4AzJ2H/CvPWJh4GPwSX3QstQ60uTsQy7vjTLHWQV1TKffO3kHKikJjQlnzw4GCCA3ytLkuk/r6YAQXHoF0P+Plq8A2wuqL6yT4AW+bBjo/h5GH4+n/g2z9B39th8MMQeZnVFYo0Oi0H74GKSsu5b/5mNh0+QVgrPxb9cgSxbQOtLkuk/nZ9BoseMkdDpn4DkQOsrqjhSk7Drn/B5vfg2K5zj3ccBEMehl43u2/gEjmrrp/fCiMepqzcziMfbefr3cdo5e/Dpz8fRp+OIVaXJVJ/eRkwZxgUnYIrZ8KVz1ldkXMZBqRugi3vwY9LwV5qPt6yLQyYDIMehDaxlpYIQFkxHN8H5SVWV1J/Aa0htJP79emUnjG/9/Yy175OaCenny5UGGmGDMNg5uJdfLolFT9vLz54cAjDO7e1uiyR+jMM+Oh2OHh2NOShRPD24NONBVmw/QPY+j7kpZ190AbdroMhU6HTmMb5ILWXQ/Z+SNsOadsgfTtk/nAuKLkz/2DzVFjkQOg4EDomQHBHaCozDMvL4Pieqt/7Y7vBKHf9a982zzxd6ER1/fxWz4gHefXrfXy6JRUvG7x+92UKIuL+tr1vBhFvf7jlbc8OIgCt2sPlT8PIJ80G1y3vQvIq2P+leQvtBIMeggH3QgsnXU/KMOBUivmhl7YN0pIgYweUFFy8bUBrCHDjXwgLjkNxHhxeY94qBLY3Q0nHgedCSmM0FBsGnEiG9KSz3/vtkPE9lJ25eNsWoeDfyrX1+Fl3Ol8jIx5i3neH+ePnuwGYdWtf7h4SY3FFIg10IhnmjoLS0zBuFgx/xOqKrJF9wDyFs+Nj84MUwKeF+RvskIchor9jz3c6u+pv3WnboTD74u18A8+OIAw4N4LQOrbpjCDUhyOjDm3izgaTsyElon/DP6zzM8+FjorvfdGpi7fzCzK/9xWv3dRGbxyg0zTNyNKkNKYv3AHA0+O68+hVXawtSKSh7OWw4AZI2QBxo2HKMvc7z+9sJadh5/8zg8mxH849HjXEXLOk983g4191n+J8SN9x7oMvbTvkplz83F4+EN7nvJGBBGjXHbyawVIAJYWQueu8kaHtcOLQxdvZvKBdT+g4wPz+RA6E8N41j9adOWWOeJz/vc9Pv3g7bz/o0Pfcc3ZMgLZdPObfu8JIM7FyXxYPf7CVMrvBAyPj+N2EXlpd1d1VDN2GdnLL34ScYt3fIfF35m+Iv1zXNBo4mwrDgJSN5imc3cvOa3gNg4FTIDjy3LD/8X1ANf/Fh3Wr+lt/eB/N3DnfmZNnv4fbz41i5GdcvJ23P0T0M7+XkQPMlYErRlxyDlbzxDZo3/Ps9/5sqGnfG3z8XP6WrKIw0gxsTznJve9u4kxpOTddFsnf7rwML69m+uHlSVb+GVa/DD0mwB0LPL9P4kLHdsM7V5izNm58AwZOtrqipiv/GGz/0OytqWx4vUBwVNXf5iMvgwDNsHNYXnrV0yvp2y99WYLWsVVHmyL6u77vo4lRGPFwpwpLuPLVVZwqLOXybu14b8og/Hw8Y1ivWTu+H+YOPzeFr8/tcOs7zWO4HKCsBN4bYw6bd7sO7v60+Y4OOaK8zGxwTfrIDHHnN2MGhVtdnWeqGMGs6D/J+B78g8773g+AwDCrq7ScZtN4uMTdxzhVWEqnsEDe+tlABRFPYBjw5dNmEAnvazba/fAZ+LaAia97zDnkWq15xQwiLULN96wgUjfePtBzonmTxmGzQdvO5q3fHVZX4/aawf9unmnVvuMATOgXQUs/ZUqPsHupOY3T2x8m/Z8559/mBUn/ByueNcOKJzu6FdbONu9P+Jt+oxdpRvQp5oZKy+2s2W+Gkat6tLe4GnGK4gL46nnz/qgnITTevJUVwZJpsPkdc4Tkmj945mhBSSEs+YU5xbLvHebMEBFpNjQy4oa2HjlJfnEZoYF+9ItqbXU54gxr/mI2ILaOhVHTzz3e/y5zlADMGSarX7GkPJf77x/M2QdBEXD9X6yuRkQamcKIG1q1LwuAK7u1w1uzZ9zf8f2w4U3z/viXzRGQ8w16wFz0C2DVn2Hd641bn6slr4JNb5n3b3rDeSuLiojbUBhxQ9/uPRtGdIrG/VU2rZaas0e6j69+u+GPwJjfmvcTfwub3228Gl2pKBeWPmreH/QgdLnG2npExBIKI24m9UQhB7IK8PaycUXXdlaXIw21+9/nmlave6n2bS//NYx+yry//NeQ9E+Xl+dyK2ZC3lFoEw/X/tHqakTEIgojbqbiFE1CTBtCWjazxbA8TXEBfPUb835F0+qljPktDDt7jZZlj8Ouz1xXn6vt/QJ2fATY4Ja3mt1iUCJyjsKImzl3ikajIm5v7avVN63WxmaDcX+GhPvBsMPin5sf6u6m4Dgse8K8P/JXEDPM2npExFIKI27kTEk56w/lADBG/SLuLfsArH/DvH/dSxc3rdbGZoMb/gb97jKnwv7rfjj4jUvKdAnDgM+nm1eKbd8brvqN1RWJiMUURtzIxuQcisvsRIYE0D08yOpypL4MA5afbVrtOq7mptXaeHnBTW9Cr5vM5b8/vReOfOf8Wl1h50LY+zl4+ZqnZy680qyINDsKI27k/Fk0ujKvG9v9b0heaTatjn+p/ouYefvAre+ZgaasCD6eBKlbnFurs+UeheXPmPevfM684qmINHsKI27CMAxWnm1eHdNdp2jcVsnp85pWp0Nop4Y9n48f3PkhxF8BJQXwz9vMC3Y1RXY7/PtRKM6FqMEwcrrVFYlIE6Ew4iYOZhVw9OQZ/Hy8GNGlrdXlSH1VrrQaY86gcQbfALj7E4gZbn7Q/98tkLXHOc/tTFvnmdOYfVrAzW+ZIzsiIiiMuI2KUzTDOrXVhfHcVZWm1WpWWm0Iv0C45/+Zly0vzIEPb4KcQ857/obKPghfn1207doXIayLtfWISJOiMOImzp2i0ZRet1SlaXVs/ZpWLyUgGH62GML7QMEx+OBGOJXi/NdxVHkZLJ0GZWfM00mDp1pdkYg0MQojbiCvqJStR04Cukqv29qz7Lym1Zddd+XdlqEweSm07WqubPrBRMhLd81r1dX6v8PRLeAfAjfPMWcCiYicR/8ruIG1+7Mpsxt0ahdIbNtAq8sRR5WchhVnm1ZH/qrhTauX0qod3LcM2sTBySPmKZuC4659zZpk7oKVZy/yN/5lCImypg4RadIURtyAZtG4uTWvmqMUzmxavZTgSJiyDII7QvZ+s6m18ETjvHaFsmJY/Avz1FSPCdD/rsZ9fRFxGwojTZzdblRej0anaNxQ9gFY/w/z/nUvgV/LxnvtNrFmIAlsD8d2mdN+i/Ia7/VX/hmyfoSWYTDhNdedmhIRt6cw0sT9kJ5LdkEJrfx9GBwXanU54gjDgC+fOa9p9frGryGsC0z5N7QIhfTt5sJoJadd/7opG2H96+b9iX83Tx2JiNRAYaSJq5jSO6pLGH4+OlxuZc8yOPQtePuZoyJWjQyE94LJS8wG0pT18Ok9UFrkutcrLoAl08wL+fW/B3pOcN1riYhH0IIVTdzKvRWnaPSbpVup0rQ6Hdp2trQcIi+Dn30GH95sLjz20e3mKqiukPE9nDwMwVHmcvciIpegMNKEHc8v5vujuQBcqeZV91LRtBrSiE2rlxI9BO75FD66A46sNW+udPObEBDi2tcQEY+gMNKErd5vTsfsHRlMeHCAxdVInWUfPNe0Or6Rm1YvJf5yeOBL+GER2Mtd9zrRg6HTla57fhHxKAojTVjFKZoxmkXjPgwDvjy70mqXa61pWr2UjgPNm4hIE6GOyCaqtNzOmgPmyIim9LqRPf8517TqypVWRUQ8iMJIE7Xtp5PkF5URGuhH/6jWVpfjfMd2w9rZjbvuhauVnIavzltp1eqmVRERN6HTNE1UxaqrV3Rrh7eXB/52/fmTkLoRDiSaszz8PGCZ+7V/hdzUs02rM6yuRkTEbWhkpIk6N6XXA0/RFJ6Ao5vN+ynr4dN7XbvuRWM4v2n1ullNq2lVRKSJUxhpgo6eLGT/sQK8bHB51zCry3G+5FXmglitOoBvoHk123/dD+WlVldWPxUrrZaXQJdroMcNVlckIuJWFEaaoJX7zMbVhNg2tG7pZ3E1LnDwv+affW+Huz8BnwDY/yUsmgrlZdbWVh97P4dD/z3btPqKmlZFRBykMNIEefQpGsOAg9+Y97teC52ugEn/BC9f2L0Ulj0GdrulJTqkpBBWzDTvj3hCTasiIvWgMNLEFJWWs/5QNgBXeeKqq8d+gIJM8G0JMcPNx7peC3e8DzZv+P4TWP6UGVrcQWXTajSMfsrqakRE3JLCSBOzITmHolI7ESEB9OgQZHU5zlcxKhJ/Ofj4n3u850S45W3ABlvnw9f/0/QDSc6hc1emVdOqiEi9KYw0MRWnaK7s3h6bJ/YeVPSLdLnm4q/1uwNuPPvhvuENWPnnxqvLUYYBy58+r2lVV6YVEakvhZEmxDAMvvXkJeCL8yFlg3m/y9XVbzNwitkECrDmFXNhtKZITasiIk6jMNKEHDpewNGTZ/Dz9mJkl7ZWl+N8h9eAvQxCO0Nop5q3G/oLuOb35v3//gE2vtUo5dVZ7lE1rYqIOJHCSBNSMSoytFMoLf08cHHcA4nmn9WdornQqCfhimfN+yuehW0LXFZWnZWXwYY34Y0haloVEXGieoWROXPmEB8fT0BAAAkJCaxdu7bGbe+//35sNttFt969e9e7aE+1cq+5vohHnqIxjNr7Rapz5UwY8bh5/z/T4fuFLimtTtKT4L0x5rVnSk9D9DCYvFRNqyIiTuBwGFm4cCHTp0/n+eefJykpidGjRzN+/HhSUlKq3f7vf/87GRkZlbfU1FRCQ0O54447Gly8J8krKmXLkROAh07pzT4AuSng7Q9xo+q2j80G1/4RBk8FDFj6S9j9b5eWeZHifPjyOXh3DGR8DwEhMPF1eOBLCOvSuLWIiHgoh8PI7Nmzeeihh5g6dSo9e/bktddeIzo6mrlz51a7fUhICB06dKi8bd26lZMnT/LAAw80uHhP8t2BbMrsBp3CAokL84CLxl2oYkpv3EjHRhNsNhj/F7jsXjDK4bOHYP/XrqnxQnu/gDeHwqa55vL1fe+Ax7ZCwn3gpTOcIiLO4tD/qCUlJWzbto2xY8dWeXzs2LGsX7++Ts8xb948rrnmGmJjY2vcpri4mLy8vCo3T+fRq64CHHSgX+RCXl5w4z+g961gL4WFPzOvb+MquUfNi/d9eg/kpUGbOPjZYrjtPWjlocdHRMRCDoWR7OxsysvLCQ8Pr/J4eHg4mZmZl9w/IyODL7/8kqlTp9a63axZswgJCam8RUdHO1Km27Hbjcrr0Xhkv0hJIRxZZ96vTxgB8PKGW9+B7jdAeTF8cjekbHRejQD2ctg41xwN2fs5ePmYDaqPbKx5KrKIiDRYvcaaL1yMyzCMOi3QtWDBAlq3bs3NN99c63YzZ84kNze38paamlqfMt3GD+m5ZBcUE+jnzeC4UKvLcb6f1pkBIiQawrrV/3m8fc1l4zuPgdJC+OgOSNvunBrTk8y+kBXPQUkBRA+Fad/B1b8D3xbOeQ0REamWQ2EkLCwMb2/vi0ZBsrKyLhotuZBhGMyfP5/Jkyfj51f7lWj9/f0JDg6ucvNkFbNoRnUNw8/HA3sRKvpFulzd8MXBfPxh0kcQOxKK8+Cft8KxH+v/fMUF5poh746BjB1mg+qE1+CBFdC+Z8NqFRGROnHok8/Pz4+EhAQSExOrPJ6YmMiIESNq3Xf16tUcPHiQhx56yPEqPdy3+872i3jiLBo4L4xc65zn82sJ9yyEjoPgzEn48CZzto6j9i43T8lsnGM2qPa5HR7dAoMeUIOqiEgjcvh/3BkzZvDee+8xf/589uzZw5NPPklKSgrTpk0DzFMsU6ZMuWi/efPmMXToUPr06dPwqj1IdkExO4+eAjy0efXEYcg5aPZfxF/uvOf1D4KfLYIOfeH0cfjgRjh5pG775qadbVC9G/KOQutY87lunwdBtY/wiYiI8zm8zOekSZPIycnhxRdfJCMjgz59+rB8+fLK2TEZGRkXrTmSm5vLokWL+Pvf/+6cqj3I6n3HMQzoHRlMeHCA1eU4X8WoSPQwCHDy6bYWrc2FxxbcAMf3wgcTzdMrIR2r395eDpvfhW//aPaFePmYi6pd/owWLxMRsVC91hx/5JFHeOSRR6r92oIFCy56LCQkhMLCwvq8lMfz/FM0Fauuumg2SmAYTPk3vD8eTiTDhzeaC5JdOAU3fQd8Pt1sVAWIGgITX4NwrQQsImI1nRi3UFm5nTX7zeZVjzxFU1ZsXhwPoKuT+kWqE9QBpiwzZ+vkHDR7SArN1WwpLoCvnod3rzKDiH8ITPgbPPiVgoiISBPhgVdjcx/bfjpJflEZbVr6cll0a6vLcb6UDeZ1XFqFQ7iLe4VaR8N9y2D+eMjaDf93M4z8FXz9O7MvBKDPbTBulvpCRESaGI2MWKjiFM0V3drh7dXAKa9NUeUsmmsaPqW3LkI7mYGkZZh5HZnPHjzboBoD934Gt89XEBERaYIURiy0aq8Hn6IB1/eLVKddd5iyFAJag80bRk6HRza59jSRiIg0iE7TWCTt1Bn2HcvHy2aOjHic3DTzdInNCzpd1biv3aEvPL7dXPU1OLJxX1tERBymMGKRb89eGG9gTBtat6x9RVq3dOjsqEjHQdDSgiXuA9s2/muKiEi96DSNRVZ5+lV6DzTgKr0iItKsKIxYoKi0nHWHsgEPXV+kvBSSV5n3FUZEROQSFEYssDE5h6JSOxEhAfSMCLK6HOc7utW8iF2LUIi8zOpqRESkiVMYscDKs6doruzeHltjTHltbOdfpdfL29paRESkyVMYaWSGYZy3BLwHzqIBOKh+ERERqTuFkUZ26PhpUk+cwc/bi5Fdwqwux/kKsswFxwA6j7G2FhERcQsKI42s4hTN0E6hBPp74MzqQ9+af0b0v/hidSIiItVQGGlkFeuLeOQsGqi6BLyIiEgdKIw0ovyiUrYcMa8mO8YT1xexl5+3BLyWXxcRkbpRGGlE3x3IpsxuEB8WSFxYoNXlOF/6DjhzAvxDIGqw1dWIiIibUBhpRCv3NZNTNJ2uAG8P7IcRERGXUBhpJHa7wcp95lV6PfIUDahfRERE6kVhpJH8mJ7H8fxiWvp5Mzi+jdXlOF/hCUjbat5XGBEREQcojDSSilM0o7qE4e/jgauSJq8Eww7te0FIR6urERERN6Iw0kgqpvR67imailk0V1tbh4iIuB2FkUaQU1DM90dPAeb1aDyOYahfRERE6k1hpBGs3n8cw4BeEcF0CAmwuhznO/YDFBwD30CIGW51NSIi4mYURhqB55+iOTsqEn85+PhbW4uIiLgdhREXKyu3s2a/OaX3qh4eepXeAxWnaNQvIiIijlMYcbHtKafIKyqjdUtfLov2wCm9RXmQutG8r34RERGpB4URF6s4RXNFt3Z4e9mc++SlRWC3O/c5HXV4DdjLILQzhMZbW4uIiLglrdntYqv2OalfpKzYbBRN227e0rfD8X1mw+h9y8Db1wnV1kNFv0hXXRhPRETqR2HEhdJOnWFvZj5eNri8qwP9IvZyyD5gBo60bWb4OPYDlJdcvG3Kelg7G6581nmF15Wm9IqIiBMojLjQyrOnaAbEtKFNoF/1GxkG5KaeCx3pSeatpODibVuEQseBEDkQOiZAfjp8/iSseQW6jYXIAS58N9XI3m/W7u0PsSMb97VFRMRjKIy4ULWnaE5nnzvNUhFACrMv3tm3JURcZoaPigDSJg5s5/WdGAYkr4bdS2HJNPj5avBtxHVMKkZF4kaCX8vGe10REfEoCiMuUlJmZ8vBDIba9nNb0Q/w/3abAeRUysUbe/lAeG9ztCPybPgI6w7elzg8NhvcMBtSNsDxvfDtH2Hc/7rmDVVHp2hERMQJFEZc5Mh3n7LC63ki/E/Apgu+2LarGTwqRjw69K3/iEZgW7jxH/DxnbDhTeg+HuJGNbj+SyophCPrzPtd1LwqIiL1pzDibKdS4ctn6LZvOdggz7sNwd1GnRvxiBwAASHOfc1u42DgFNj+ISz9JfxyPfgHOfc1LnTkOygvhpAYCOvq2tcSERGPpjDiLOVlsPlt+PZ/ofQ0ZXjzVtkEwsf9D3cM7+b61x/3Z0heZZ4G+uo35miJKx08b9VVm5PXTxERkWZFi545Q3oSvDfGDAGlpymLGsqE0lm8WjaJYd2jGqcG/yC4eS5gM0dI9n/l2tdTv4iIiDiJwkhDFOfDl8/Bu2Mg43vz9MvEv7N6xAfsLY8iJrQl0aGNOMskbhQMf9S8v+xxKDzhmtc5kQwnDpmNt52ucM1riIhIs6EwUl97Poc3h8KmuWDYoe8d8NhWSLifdYdOAjCyS1jj1zXmt+ZMnIJj8MUM17zGwf+af8YMd31vioiIeDyFEUflHoVP7oGF90Jemrn2x88Ww23vQStzPZH1h8x1Q0Z2adv49fkGwK1vm6MWPy6BXZ85/zUO6iq9IiLiPAojdWUvh41zzdGQfV+YH/ajZsAjG6t8KB/PL2ZvZj4AIzpbMDIC5oydy58273/xFORlOO+5y4rNi+OB+kVERMQpFEbqIj3J7AtZ8Zy5THv0UPjFWrjmBfBtUWXTilGRXhHBhNa0BHxjGP2UuYJr0SlY9pi5WqszpGyA0kJo1QHC+zjnOUVEpFlTGKlNcT6smHm2QXWH2aA64TV4YAWE96p2l3UHzTAyqqtFoyIVvH3h1nfM68Yc/Aa2LXDO854/i0ZTekVExAkURmqy9wvzlMzGOWaDap/b4dEtMOgB8Kr+22YYBusO5gAworMF/SIXatfdHL0B+Op5cxZMQx1Qv4iIiDiXwsiFctPg03vh03vMBtXWsfCzRXD7PAgKr3XXn3IKSTt1Bl9vG0PiQxup4EsY+kuIHQWlp2HpI2bvS33lHoXje8DmBZ2udFqJIiLSvCmMVLCXw8a34M0hsPfzCxpU69aoue5sv8iAmDa09Gsii9t6ecHNc8AvyOz32PBG/Z+rYkpvx0HQsomELRERcXsKIwDpO842qD57cYOqX90XLavsF7FifZHatImF6/5s3v/2T3Bsd/2ep6JfpKsujCciIs7TvMNIcQGs+A28e5XZoOofAhP+VmuDak3sdoP1h8x+EUvWF7mUAZOh23VQXgJLfgFlJY7tX15qXvsG1C8iIiJO1XzDiGHAguth45tnG1Rvg8e2wKAHa2xQrc3ujDxOFZYS6OdNv6jWzq+3oWw2mPg6tAiFzJ2w5hXH9j+6BYrzoGVbiBjgmhpFRKRZar5hxGYzmztbx8K9i+D2+ZdsUK1NxSmaYZ3a4uvdRL+tQeEwYbZ5f+1sOLq17vtWnKLpPKZeYU1ERKQmzftTpf9d8Ogm6NrwlUTXnT1FM6Kp9YtcqPct5nV0jHLzdE1JYd3201V6RUTERZp3GLHZLlpBtT6Ky8rZfNgMI02uebU61/8FgiIg5yD89w+X3r4gy7wqMUBn9YuIiIhzNe8w4iRJKacoKrUT1sqfbuGtrC7n0lq0gZvOTvHd9BYkr659+4opvRGXQat2Li1NRESaH4URJ6joFxnZpS02d1kivcs1ZrMumIuhFeXWvK1O0YiIiAspjDhBZRix6iq99XXtH6FNHOQdNa/BUx17ORz61ryvMCIiIi6gMNJA+UWlfH/UHFUYafXF8Rzl3wpueRuwwY6PzOvxXCh9B5w5Ya7BEjW4sSsUEZFmQGGkgTYln6DcbhDXtiUdWze8GbbRxQyDkU+Y9//zKzidXfXrlVN6rwTvJrLEvYiIeBSFkQb6rrJfxM1GRc531fPQvhecPm4GEsM497WDieafOkUjIiIuojDSQOsPeUAY8fE3T9d4+ZoXCdy50Hy88ASkbTPva0qviIi4SL3CyJw5c4iPjycgIICEhATWrl1b6/bFxcU8//zzxMbG4u/vT+fOnZk/f369Cm5KsvKK2H+sAJsNhndqgtejcUREP7jyWfP+8mcg9ygkrzSXym/fC0I6WlufiIh4LIebABYuXMj06dOZM2cOI0eO5O2332b8+PHs3r2bmJiYave58847OXbsGPPmzaNLly5kZWVRVlbW4OKtVnFhvN6RwbQJ9LO4GicY+STsWwFpW+Hfj5oLo4FO0YiIiEs5HEZmz57NQw89xNSpUwF47bXX+Oqrr5g7dy6zZs26aPsVK1awevVqkpOTCQ0NBSAuLq5hVTcR6zyhX+R83j7m6Zq3RplX6LWdHThTGBERERdy6DRNSUkJ27ZtY+zYsVUeHzt2LOvXr692n2XLljFo0CBeeeUVOnbsSLdu3fj1r3/NmTNn6l91E2AYhvuuL1KbsC5w7YvmfcMOvoHmjBsREREXcWhkJDs7m/LycsLDq17dNjw8nMzMzGr3SU5O5rvvviMgIIAlS5aQnZ3NI488wokTJ2rsGykuLqa4uLjy73l5eY6U2SiO5BSSnluEn7cXg+NCrS7HuQZPNRtZD6+GTleYDa4iIiIuUq8G1guXPDcMo8Zl0O12OzabjY8++oghQ4Zw/fXXM3v2bBYsWFDj6MisWbMICQmpvEVHR9enTJeqmNI7MLY1Lfy8La7Gyby84LZ5MHL6uVESERERF3EojISFheHt7X3RKEhWVtZFoyUVIiIi6NixIyEhIZWP9ezZE8MwOHr0aLX7zJw5k9zc3MpbamqqI2U2ivWeeIrmfK3awbV/gLCuVlciIiIezqEw4ufnR0JCAomJiVUeT0xMZMSIEdXuM3LkSNLT0ykoKKh8bP/+/Xh5eREVFVXtPv7+/gQHB1e5NSXldqNyJo3bLQEvIiLSxDh8mmbGjBm89957zJ8/nz179vDkk0+SkpLCtGnTAHNUY8qUKZXb33PPPbRt25YHHniA3bt3s2bNGp5++mkefPBBWrRww+XTgd3peeSeKSXI34d+HUMuvYOIiIjUyOGpvZMmTSInJ4cXX3yRjIwM+vTpw/Lly4mNjQUgIyODlJSUyu1btWpFYmIijz/+OIMGDaJt27bceeed/OlPf3Leu2hkFf0iQzu1xcdbi9iKiIg0hM0wzr8QSdOUl5dHSEgIubm5TeKUzeR5m1h7IJsXJvbigZHxVpcjIiLSJNX181u/1juoqLSczYdPADDKUxY7ExERsZDCiIO2p5ykuMxO+yB/urRvZXU5IiIibk9hxEHnLwFf09oqIiIiUncKIw5ad9Cc0juis5tfpVdERKSJUBhxQF5RKTuPngI86OJ4IiIiFlMYccDGQznYDegUFkhka/dcI0VERKSpURhxQOWqqxoVERERcRqFEQd8V9m8qn4RERERZ1EYqaNjeUUczCrAZoNhnRRGREREnEVhpI4qpvT27RhC65Z+FlcjIiLiORRG6ujclF71i4iIiDiTwkgdGIZROTKiJeBFREScS2GkDpKzT5OZV4SfjxeD4tpYXY6IiIhHURipg4pRkUGxbQjw9ba4GhEREc+iMFIH51+PRkRERJxLYeQSyu0GG7TYmYiIiMsojFzCD2m55BWVERTgQ9+OIVaXIyIi4nEURi5h3SHzFM3wTm3x9rJZXI2IiIjnURi5BPWLiIiIuJbCSC2KSsvZcuQkoDAiIiLiKgojtdj200lKyuyEB/vTuV2g1eWIiIh4JIWRWlSeoukchs2mfhERERFXUBiphfpFREREXE9hpAa5haXsSssFFEZERERcSWGkBhuSc7Ab0LldIB1CAqwuR0RExGMpjNRg/SGdohEREWkMCiM1UL+IiIhI41AYqUZmbhGHjp/GywbDOrW1uhwRERGPpjBSjYpRkb5RrQlp4WtxNSIiIp5NYaQa59YX0aiIiIiIqymMXMAwjMqL441Sv4iIiIjLKYxc4NDxAo7lFePv48XA2DZWlyMiIuLxFEYusO5gDgCD40IJ8PW2uBoRERHPpzByge/O9ouM6KJ+ERERkcagMHKesnI7G5PNkRH1i4iIiDQOhZHz7ErLJb+ojOAAH3pHhlhdjoiISLOgMHKe9YfMUZHhndvi7WWzuBoREZHmQWHkPBXri+gUjYiISONRGDmrqLScrT+dBGCEwoiIiEijURg5a+uRk5SU2YkICaBTWKDV5YiIiDQbCiNnVU7p7RyGzaZ+ERERkcaiMHLW+ool4LtqfREREZHGpDACnCosYVdaLmCOjIiIiEjjURgBNibnYBjQtX0rwoMDrC5HRESkWVEY4Vy/yEjNohEREWl0CiPA+rMXx1MYERERaXzNPoyknzpDcvZpvGwwtFOo1eWIiIg0O80+jFSsuto/ujXBAb4WVyMiItL8NPswUnE9mpGaRSMiImKJZh1GDMNQ86qIiIjFmnUYOZhVwPH8YgJ8vRgY29rqckRERJqlZh1GKkZFBseF4u/jbXE1IiIizVOzDiPrNKVXRETEcj5WF2Cle4fGEBESwFXd21tdioiISLPVrMPIVT3ac1UPBRERERErNevTNCIiImI9hRERERGxlMKIiIiIWEphRERERCxVrzAyZ84c4uPjCQgIICEhgbVr19a47apVq7DZbBfd9u7dW++iRURExHM4HEYWLlzI9OnTef7550lKSmL06NGMHz+elJSUWvfbt28fGRkZlbeuXbvWu2gRERHxHA6HkdmzZ/PQQw8xdepUevbsyWuvvUZ0dDRz586tdb/27dvToUOHypu3t1Y8FREREQfDSElJCdu2bWPs2LFVHh87dizr16+vdd8BAwYQERHB1VdfzcqVK2vdtri4mLy8vCo3ERER8UwOhZHs7GzKy8sJDw+v8nh4eDiZmZnV7hMREcE777zDokWLWLx4Md27d+fqq69mzZo1Nb7OrFmzCAkJqbxFR0c7UqaIiIi4kXqtwGqz2ar83TCMix6r0L17d7p371759+HDh5Oamsqrr77K5ZdfXu0+M2fOZMaMGZV/z8vLUyARERHxUA6NjISFheHt7X3RKEhWVtZFoyW1GTZsGAcOHKjx6/7+/gQHB1e5iYiIiGdyKIz4+fmRkJBAYmJilccTExMZMWJEnZ8nKSmJiIgIR15aREREPJTDp2lmzJjB5MmTGTRoEMOHD+edd94hJSWFadOmAeYplrS0ND788EMAXnvtNeLi4ujduzclJSX885//ZNGiRSxatMi570RERETcksNhZNKkSeTk5PDiiy+SkZFBnz59WL58ObGxsQBkZGRUWXOkpKSEX//616SlpdGiRQt69+7NF198wfXXX1/n1zQMA0CzakRERNxIxed2xed4TWzGpbZoAo4ePaoGVhERETeVmppKVFRUjV93izBit9tJT08nKCioxlk79VExSyc1NbVZNMk2p/er9+q5mtP71Xv1XM3l/RqGQX5+PpGRkXh51dymWq+pvY3Ny8ur1kTVUM1txk5zer96r56rOb1fvVfP1Rzeb0hIyCW30VV7RURExFIKIyIiImKpZh1G/P39eeGFF/D397e6lEbRnN6v3qvnak7vV+/VczW393spbtHAKiIiIp6rWY+MiIiIiPUURkRERMRSCiMiIiJiKYURERERsZTHh5E5c+YQHx9PQEAACQkJrF27ttbtV69eTUJCAgEBAXTq1Im33nqrkSptmFmzZjF48GCCgoJo3749N998M/v27at1n1WrVmGz2S667d27t5Gqrp/f//73F9XcoUOHWvdx1+MaFxdX7TF69NFHq93e3Y7pmjVrmDhxIpGRkdhsNpYuXVrl64Zh8Pvf/57IyEhatGjBlVdeyY8//njJ5120aBG9evXC39+fXr16sWTJEhe9g7qr7b2Wlpby7LPP0rdvXwIDA4mMjGTKlCmkp6fX+pwLFiyo9ngXFRW5+N3U7lLH9f7777+o5mHDhl3yeZvicYVLv9/qjpHNZuMvf/lLjc/ZVI+tq3h0GFm4cCHTp0/n+eefJykpidGjRzN+/PgqF/I73+HDh7n++usZPXo0SUlJ/OY3v+GJJ55wiysMr169mkcffZSNGzeSmJhIWVkZY8eO5fTp05fcd9++fWRkZFTeunbt2ggVN0zv3r2r1Lxr164at3Xn47ply5Yq7zMxMRGAO+64o9b93OWYnj59mv79+/PGG29U+/VXXnmF2bNn88Ybb7BlyxY6dOjAtddeS35+fo3PuWHDBiZNmsTkyZP5/vvvmTx5MnfeeSebNm1y1duok9rea2FhIdu3b+e3v/0t27dvZ/Hixezfv58bb7zxks8bHBxc5VhnZGQQEBDgirdQZ5c6rgDXXXddlZqXL19e63M21eMKl36/Fx6f+fPnY7PZuO2222p93qZ4bF3G8GBDhgwxpk2bVuWxHj16GM8991y12z/zzDNGjx49qjz2i1/8whg2bJjLanSVrKwsAzBWr15d4zYrV640AOPkyZONV5gTvPDCC0b//v3rvL0nHddf/epXRufOnQ273V7t1931mBqGYQDGkiVLKv9ut9uNDh06GC+99FLlY0VFRUZISIjx1ltv1fg8d955p3HddddVeWzcuHHGXXfd5fSa6+vC91qdzZs3G4Dx008/1bjN+++/b4SEhDi3OCer7r3ed999xk033eTQ87jDcTWMuh3bm266yRgzZkyt27jDsXUmjx0ZKSkpYdu2bYwdO7bK42PHjmX9+vXV7rNhw4aLth83bhxbt26ltLTUZbW6Qm5uLgChoaGX3HbAgAFERERw9dVXs3LlSleX5hQHDhwgMjKS+Ph47rrrLpKTk2vc1lOOa0lJCf/85z958MEHL3nBSHc8phc6fPgwmZmZVY6dv78/V1xxRY0/w1Dz8a5tn6YoNzcXm81G69ata92uoKCA2NhYoqKimDBhAklJSY1TYAOtWrWK9u3b061bNx5++GGysrJq3d5TjuuxY8f44osveOihhy65rbse2/rw2DCSnZ1NeXk54eHhVR4PDw8nMzOz2n0yMzOr3b6srIzs7GyX1epshmEwY8YMRo0aRZ8+fWrcLiIignfeeYdFixaxePFiunfvztVXX82aNWsasVrHDR06lA8//JCvvvqKd999l8zMTEaMGEFOTk6123vKcV26dCmnTp3i/vvvr3Ebdz2m1an4OXXkZ7hiP0f3aWqKiop47rnnuOeee2q9iFqPHj1YsGABy5Yt45NPPiEgIICRI0dy4MCBRqzWcePHj+ejjz7i22+/5a9//StbtmxhzJgxFBcX17iPJxxXgA8++ICgoCBuvfXWWrdz12NbX25x1d6GuPA3SMMwav2tsrrtq3u8KXvsscfYuXMn3333Xa3bde/ene7du1f+ffjw4aSmpvLqq69y+eWXu7rMehs/fnzl/b59+zJ8+HA6d+7MBx98wIwZM6rdxxOO67x58xg/fjyRkZE1buOux7Q2jv4M13efpqK0tJS77roLu93OnDlzat122LBhVRo/R44cycCBA/nHP/7B66+/7upS623SpEmV9/v06cOgQYOIjY3liy++qPVD2p2Pa4X58+dz7733XrL3w12PbX157MhIWFgY3t7eF6XmrKysi9J1hQ4dOlS7vY+PD23btnVZrc70+OOPs2zZMlauXElUVJTD+w8bNsztkndgYCB9+/atsW5POK4//fQT33zzDVOnTnV4X3c8pkDlDClHfoYr9nN0n6aitLSUO++8k8OHD5OYmOjwpeW9vLwYPHiw2x3viIgIYmNja63bnY9rhbVr17Jv3756/Ry767GtK48NI35+fiQkJFTOPqiQmJjIiBEjqt1n+PDhF23/9ddfM2jQIHx9fV1WqzMYhsFjjz3G4sWL+fbbb4mPj6/X8yQlJREREeHk6lyruLiYPXv21Fi3Ox/XCu+//z7t27fnhhtucHhfdzymAPHx8XTo0KHKsSspKWH16tU1/gxDzce7tn2agoogcuDAAb755pt6BWXDMNixY4fbHe+cnBxSU1Nrrdtdj+v55s2bR0JCAv3793d4X3c9tnVmVedsY/j0008NX19fY968ecbu3buN6dOnG4GBgcaRI0cMwzCM5557zpg8eXLl9snJyUbLli2NJ5980ti9e7cxb948w9fX1/jss8+segt19stf/tIICQkxVq1aZWRkZFTeCgsLK7e58P3+7W9/M5YsWWLs37/f+OGHH4znnnvOAIxFixZZ8Rbq7KmnnjJWrVplJCcnGxs3bjQmTJhgBAUFeeRxNQzDKC8vN2JiYoxnn332oq+5+zHNz883kpKSjKSkJAMwZs+ebSQlJVXOIHnppZeMkJAQY/HixcauXbuMu+++24iIiDDy8vIqn2Py5MlVZsitW7fO8Pb2Nl566SVjz549xksvvWT4+PgYGzdubPT3d77a3mtpaalx4403GlFRUcaOHTuq/AwXFxdXPseF7/X3v/+9sWLFCuPQoUNGUlKS8cADDxg+Pj7Gpk2brHiLlWp7r/n5+cZTTz1lrF+/3jh8+LCxcuVKY/jw4UbHjh3d8rgaxqX/HRuGYeTm5hotW7Y05s6dW+1zuMuxdRWPDiOGYRhvvvmmERsba/j5+RkDBw6sMtX1vvvuM6644ooq269atcoYMGCA4efnZ8TFxdX4D6epAaq9vf/++5XbXPh+X375ZaNz585GQECA0aZNG2PUqFHGF1980fjFO2jSpElGRESE4evra0RGRhq33nqr8eOPP1Z+3ZOOq2EYxldffWUAxr59+y76mrsf04qpyBfe7rvvPsMwzOm9L7zwgtGhQwfD39/fuPzyy41du3ZVeY4rrriicvsK//rXv4zu3bsbvr6+Ro8ePZpEGKvtvR4+fLjGn+GVK1dWPseF73X69OlGTEyM4efnZ7Rr184YO3assX79+sZ/cxeo7b0WFhYaY8eONdq1a2f4+voaMTExxn333WekpKRUeQ53Oa6Gcel/x4ZhGG+//bbRokUL49SpU9U+h7scW1exGcbZTj4RERERC3hsz4iIiIi4B4URERERsZTCiIiIiFhKYUREREQspTAiIiIillIYEREREUspjIiIiIilFEZERETEUgojIiIiYimFEREREbGUwoiIiIhYSmFERERELPX/AaE2RrPtR3AFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(result.history['accuracy'])\n",
    "plt.plot(result.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c2d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 4ms/step - loss: 1.4124 - accuracy: 0.7922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.412404179573059, 0.7921623587608337]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89a5725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 6ms/step - loss: 1.0183 - accuracy: 0.7012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0183262825012207, 0.7011896371841431]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66c98df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3691271e-02, 3.1950426e-01, 2.8066280e-01, ..., 5.7849467e-02,\n",
       "        1.3051696e-01, 6.3374969e-03],\n",
       "       [8.4849010e-04, 2.0961245e-03, 7.4291532e-04, ..., 4.2996434e-03,\n",
       "        1.5243342e-03, 9.8800606e-01],\n",
       "       [4.2195656e-04, 1.1944813e-04, 9.6162606e-04, ..., 1.1239087e-02,\n",
       "        1.6771106e-03, 3.1697853e-03],\n",
       "       ...,\n",
       "       [3.3352375e-02, 1.2827846e-01, 1.1135635e-02, ..., 3.5861641e-02,\n",
       "        2.0176653e-02, 7.5501120e-01],\n",
       "       [4.3657776e-02, 7.9792542e-03, 3.6163259e-02, ..., 2.5918585e-01,\n",
       "        2.6142278e-01, 4.8905341e-03],\n",
       "       [8.1802227e-02, 1.9727415e-01, 1.1602374e-01, ..., 1.1856729e-01,\n",
       "        9.5021650e-02, 1.2227939e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c90514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns the most likely class for each image\n",
    "\n",
    "y_pred = np.argmax(model_test.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "013d918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acantocyte': 0, 'elliptocyte': 1, 'hypochromic': 2, 'normal': 3, 'pencil': 4, 'spero_bulat': 5, 'stomatocyte': 6, 'targetsel': 7, 'teardrop': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 8, 3, ..., 8, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_gen.class_indices)\n",
    "y_pred[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bf4736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smae procedure for the 'actual' data\n",
    "\n",
    "Y_test_multilabel = np.argmax(Y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5873eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 3, ..., 8, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_multilabel[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7718cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_confusion_matrix = multilabel_confusion_matrix(Y_test_multilabel, y_pred)\n",
    "model_confusion_matrix = confusion_matrix(Y_test_multilabel, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7f19c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15,   3,   0,  40,   0,   0,  10,   3,   1],\n",
       "       [  1, 185,   5,  21,   0,   0,   2,  14,  15],\n",
       "       [  0,   1,   0,  29,   0,   0,   1,  12,   2],\n",
       "       [  2,   0,   0, 261,   0,   0,   2,  21,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   6],\n",
       "       [  1,   0,   0,  32,   0,  26,  18,  35,   1],\n",
       "       [  0,   0,   0,  68,   0,   0,   4,   4,   1],\n",
       "       [  0,   2,   1,  57,   0,   0,   4, 107,   0],\n",
       "       [  0,   5,   0,   7,   0,   0,   0,   0, 404]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6375571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Actual')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))  \n",
    "sns.heatmap(model_confusion_matrix, cmap='Reds', annot=True, square=True, fmt='d')\n",
    "plt.title(\"Title\")    \n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502509f",
   "metadata": {},
   "source": [
    "The model actually does realatively good job on recognizing most cell shapes other than normal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
